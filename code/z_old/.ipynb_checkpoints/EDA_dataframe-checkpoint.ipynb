{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation (static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the directory\n",
    "path_EDA = '/Users/gioelepozzi/Desktop/data/EDA'\n",
    "path_VA = '/Users/gioelepozzi/Desktop/data/annotations'\n",
    "\n",
    "l = [] # lista per unire i risultati in un DataFrame unico\n",
    "count = 1 # contatore per ciclare tutti i brani nel file con i dati di VA\n",
    "dictionary = {} # per creare il DataFrame\n",
    "\n",
    "# ciclo per ogni brano\n",
    "for csv_file in tqdm(natsorted(os.listdir(path_EDA))):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        # prendo dal nome del file il numero del brano (music_ID)\n",
    "        file_name = os.path.basename(csv_file)\n",
    "        music_ID = file_name.split('_')[0]\n",
    "        #print('file name',file_name,music_ID, VA_std.iloc[count][0])\n",
    "\n",
    "        \n",
    "        # prendo file con valori di EDA e VA\n",
    "        my_data = pd.read_csv(path_EDA + '/' + file_name, header = None)\n",
    "        VA_std = pd.read_csv(path_VA + '/static_annotations_std.csv', header = None)\n",
    "        VA_mean = pd.read_csv(path_VA + '/static_annotations.csv', header = None)\n",
    "        \n",
    "        # ci sono alcuni file EDA che non hanno il corrispettivo valore di VA\n",
    "        # perchè per validare i valori di VA hanno rifatto ascoltare un brano e se davano valori di VA\n",
    "        # diversi di più di 0.25 venivano scartati\n",
    "        if music_ID != VA_std.iloc[count][0]:\n",
    "            continue\n",
    "\n",
    "        # prendo valori di VA dai file qua sopra\n",
    "        v_std = VA_std.iloc[count][2]\n",
    "        a_std = VA_std.iloc[count][1]\n",
    "        v_mean = VA_mean.iloc[count][2]\n",
    "        a_mean = VA_mean.iloc[count][1]\n",
    "        count = count + 1\n",
    "        \n",
    "        # prendo ID della persona dai file EDA\n",
    "        subject_ID = my_data.loc[0]\n",
    "        \n",
    "        # creo un vettore dei soggetti, per ogni brano. Per ogni soggetto calcolo features\n",
    "        subject_vector = []\n",
    "        td_mean_vector = []\n",
    "        td_std_vector = []\n",
    "        td_kurt_vector = []\n",
    "        td_skew_vector = []\n",
    "        psd_vector = []\n",
    "        td_mean_vector = []\n",
    "        td_min_vector = []\n",
    "        td_max_vector = []\n",
    "        td_range_vector = []\n",
    "        td_median_vector = []\n",
    "        td_std_dev_vector = []\n",
    "        td_sum_vector = []\n",
    "        td_AUC_vector = []\n",
    "        td_RMSSD_vector = []\n",
    "        td_SDSD_vector = []\n",
    "        \n",
    "        ZCR_vector = []\n",
    "        \n",
    "        fd_mean_vector = []\n",
    "        fd_std_vector = []\n",
    "        fd_kurt_vector = []\n",
    "        fd_skew_vector = []\n",
    "        fd_min_vector = []\n",
    "        fd_max_vector = []\n",
    "        fd_range_vector = []\n",
    "        \n",
    "        fd_powerinband_vector1 = []\n",
    "        fd_powerinband_vector2 = []\n",
    "        fd_powerinband_vector3 = []\n",
    "        fd_powerinband_vector4 = []\n",
    "        fd_powerinband_vector5 = []\n",
    "        \n",
    "        fd_peakinband_vector1 = []\n",
    "        fd_peakinband_vector2 = []\n",
    "        fd_peakinband_vector3 = []\n",
    "        fd_peakinband_vector4 = []\n",
    "        fd_peakinband_vector5 = []\n",
    "\n",
    "        \n",
    "        for i in range(1,len(subject_ID)):\n",
    "            subject_vector.append(int(subject_ID[i]))\n",
    "            \n",
    "            # modifica del segnale per fare resampling, filtraggio, e prendere la parte di phasic\n",
    "            eda_data = [] # rappresenta la colonna con il segnale nei file EDA, uno per ogni soggetto\n",
    "            s = my_data.iloc[:][i]\n",
    "            for k in range(1, len(s)):\n",
    "                eda_data.append(s[k])\n",
    "                \n",
    "            fs = 50\n",
    "            times = np.arange(len(eda_data))/fs\n",
    "            \n",
    "            # prendo la parte phasic del segnale\n",
    "            phasic = initialize_signal(eda_data, fs = 50, s_type = 'eda')\n",
    "            \n",
    "            frequency_signal = np.abs(np.fft.fft(phasic))\n",
    "            frequency = np.fft.fftfreq(phasic.size, d=1/fs)\n",
    "            \n",
    "            # funzioni statistiche nel tempo\n",
    "            td_mean_vector.append(np.mean(phasic))\n",
    "            td_std_vector.append(np.std(phasic))\n",
    "            td_kurt_vector.append(stats.kurtosis(phasic))\n",
    "            td_skew_vector.append(stats.skew(phasic))\n",
    "            psd_vector.append(signal.periodogram(phasic))\n",
    "            \n",
    "            # richiamo delle funzioni che calcolano le features e metto in un vettore\n",
    "            td_min_vector.append(td_min(phasic))\n",
    "            td_max_vector.append(td_max(phasic))\n",
    "            td_range_vector.append(td_range(phasic))\n",
    "            td_median_vector.append(td_median(phasic))\n",
    "            td_sum_vector.append(td_sum(phasic))\n",
    "            td_AUC_vector.append(td_AUC(phasic))\n",
    "            td_RMSSD_vector.append(td_RMSSD(phasic))\n",
    "            td_SDSD_vector.append(td_SDSD(phasic))\n",
    "            \n",
    "            ZCR_vector.append(((phasic[:-1] * phasic[1:]) < 0).sum())\n",
    "            \n",
    "            fd_mean_vector.append(np.mean(frequency_signal))\n",
    "            fd_std_vector.append(np.std(frequency_signal))\n",
    "            fd_kurt_vector.append(stats.kurtosis(frequency_signal))\n",
    "            fd_skew_vector.append(stats.skew(frequency_signal))\n",
    "            fd_min_vector.append(frequency_signal.min())\n",
    "            fd_max_vector.append(frequency_signal.max())\n",
    "            fd_range_vector.append(frequency_signal.max()-frequency_signal.min())\n",
    "            \n",
    "            # 0-0.1-0.2-0.3-0.4-0.5 come in PMEmo\n",
    "            fd_powerinband_vector1.append(fd_powerinband(phasic,0,0.1))\n",
    "            fd_powerinband_vector2.append(fd_powerinband(phasic,0.1,0.2))\n",
    "            fd_powerinband_vector3.append(fd_powerinband(phasic,0.2,0.3))\n",
    "            fd_powerinband_vector4.append(fd_powerinband(phasic,0.3,0.4))\n",
    "            fd_powerinband_vector5.append(fd_powerinband(phasic,0.4,0.5))\n",
    "            \n",
    "            fd_peakinband_vector1.append(fd_peakinband(phasic,0,0.1))\n",
    "            fd_peakinband_vector2.append(fd_peakinband(phasic,0.1,0.2))\n",
    "            fd_peakinband_vector3.append(fd_peakinband(phasic,0.2,0.3))\n",
    "            fd_peakinband_vector4.append(fd_peakinband(phasic,0.3,0.4))\n",
    "            fd_peakinband_vector5.append(fd_peakinband(phasic,0.4,0.5))\n",
    "            \n",
    "            #print('min vector ', td_min_vector, '\\n\\n')\n",
    "            \n",
    "            #np.seterr(divide='ignore', invalid='ignore')\n",
    "            #td_min_vector_norm = (td_min_vector - np.min(td_min_vector))/np.ptp(td_min_vector)\n",
    "            \n",
    "            \n",
    "        # creo un dizionario\n",
    "        labels = [\n",
    "            'music_ID',\n",
    "            'subject_ID',\n",
    "            'valence(mean)',\n",
    "            'arousal(mean)',\n",
    "            'valence(std)',\n",
    "            'arousal(std)',\n",
    "            'td_mean',\n",
    "            'td_std',\n",
    "            'td_kurt',\n",
    "            'td_skew',\n",
    "            'td_min',\n",
    "            'td_max',\n",
    "            'td_range',\n",
    "            'td_median',\n",
    "            'td_sum',\n",
    "            'td_AUC',\n",
    "            'td_RMSSD',\n",
    "            'td_SDSD',\n",
    "            'ZCR',\n",
    "            'fd_mean',\n",
    "            'fd_std',\n",
    "            'fd_kurt',\n",
    "            'fd_skew',\n",
    "            'fd_min',\n",
    "            'fd_max',\n",
    "            'fd_range',\n",
    "            'fd_powerinband1',\n",
    "            'fd_powerinband2',\n",
    "            'fd_powerinband3',\n",
    "            'fd_powerinband4',\n",
    "            'fd_powerinband5',\n",
    "            'fd_peakinband1',\n",
    "            'fd_peakinband2',\n",
    "            'fd_peakinband3',\n",
    "            'fd_peakinband4',\n",
    "            'fd_peakinband5'\n",
    "        ]\n",
    "        values = [\n",
    "            music_ID,\n",
    "            subject_vector,\n",
    "            v_mean,\n",
    "            a_mean,\n",
    "            v_std,\n",
    "            a_std,\n",
    "            td_mean_vector,\n",
    "            td_std_vector,\n",
    "            td_kurt_vector,\n",
    "            td_skew_vector,\n",
    "            td_min_vector,\n",
    "            td_max_vector,\n",
    "            td_range_vector,\n",
    "            td_median_vector,\n",
    "            td_sum_vector,\n",
    "            td_AUC_vector,\n",
    "            td_RMSSD_vector,\n",
    "            td_SDSD_vector,\n",
    "            ZCR_vector,\n",
    "            fd_mean_vector,\n",
    "            fd_std_vector,\n",
    "            fd_kurt_vector,\n",
    "            fd_skew_vector,\n",
    "            fd_min_vector,\n",
    "            fd_max_vector,\n",
    "            fd_range_vector,\n",
    "            fd_powerinband_vector1,\n",
    "            fd_powerinband_vector2,\n",
    "            fd_powerinband_vector3,\n",
    "            fd_powerinband_vector4,\n",
    "            fd_powerinband_vector5,\n",
    "            fd_peakinband_vector1,\n",
    "            fd_peakinband_vector2,\n",
    "            fd_peakinband_vector3,\n",
    "            fd_peakinband_vector4,\n",
    "            fd_peakinband_vector5\n",
    "        ]\n",
    "        \n",
    "        # popolo il dizionario\n",
    "        for j in range(len(labels)):\n",
    "            dictionary[labels[j]] = values[j]\n",
    "        \n",
    "        # creo il dataframe\n",
    "        df = pd.DataFrame(dictionary)\n",
    "        l.append(df)\n",
    "        \n",
    "        continue\n",
    "\n",
    "\n",
    "results = pd.concat(l, ignore_index=True)\n",
    "\n",
    "\n",
    "# normalizzazione [0,1] per ogni feature, dalla colonna td_mean (7) in poi\n",
    "for n in range(6,len(df.columns)) :\n",
    "    if labels[n] == 'ZCR': # per ZCR, non voglio normalizzare questa colonna\n",
    "        continue\n",
    "    a = results.iloc[:,n]\n",
    "    b = (a - np.min(a))/np.ptp(a)\n",
    "    results.update(b)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_with_overlap(a, window, stride):\n",
    "    nrows = ((a.size-window)//stride)+1 # // floor division\n",
    "    n = a.strides[0]\n",
    "    # create a view into the array a with the given shape and strides\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=(nrows,window), strides=(stride*n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dynamic_features(path_EDA, path_VA, window, stride):\n",
    "    \n",
    "    feature_set = pd.DataFrame()\n",
    "    count = 1\n",
    "    \n",
    "    for eda_file in tqdm(natsorted(os.listdir(path_EDA))):\n",
    "        if eda_file.endswith('.csv'):\n",
    "            \n",
    "            file_name = os.path.basename(eda_file)\n",
    "            id = file_name.split('_')[0]\n",
    "            data = pd.read_csv(path_EDA + '/' + file_name, header = None)\n",
    "            VA_std = pd.read_csv(path_VA + '/static_annotations_std.csv', header = None)\n",
    "            VA_mean = pd.read_csv(path_VA + '/static_annotations.csv', header = None)\n",
    "            \n",
    "            subject_vector = []\n",
    "            \n",
    "            if id!= VA_std.iloc[count][0]:\n",
    "                continue\n",
    "            \n",
    "            v_std = VA_std.iloc[count][2]\n",
    "            a_std = VA_std.iloc[count][1]\n",
    "            v_mean = VA_mean.iloc[count][2]\n",
    "            a_mean = VA_mean.iloc[count][1]\n",
    "            count = count + 1\n",
    "            subject_ID = data.loc[0]\n",
    "            \n",
    "            for i in range(1,len(subject_ID)):\n",
    "                subject_vector.append(int(subject_ID[i]))\n",
    "                eda_data = [] # rappresenta la colonna con il segnale nei file EDA, uno per ogni soggetto\n",
    "                s = my_data.iloc[:][i]\n",
    "                for k in range(1, len(s)):\n",
    "                    eda_data.append(s[k])\n",
    "                \n",
    "                sr = 50\n",
    "                times = np.arange(len(eda_data))/sr\n",
    "                phasic = initialize_signal(eda_data, fs = sr, s_type = 'eda')\n",
    "                \n",
    "                times = np.arange(len(phasic))/sr\n",
    "                frames = window_with_overlap(phasic, window, stride)\n",
    "                time_frames = window_with_overlap(times, window, stride)\n",
    "                \n",
    "                for fidx, frame in enumerate(frames):\n",
    "                    \n",
    "                    feature = {}\n",
    "                    frame_time = fidx*0.5+1\n",
    "                    times = time_frames[fidx]\n",
    "                    frequency_signal = np.abs(np.fft.fft(frame))\n",
    "                    frequency = np.fft.fftfreq(frame.size, d=1/sr)\n",
    "                                        \n",
    "                    #print(fidx, frame_time, subject_ID)\n",
    "\n",
    "\n",
    "                    feature['music_ID'] = id\n",
    "                    feature['subject_ID'] = subject_ID\n",
    "                    feature['frame_time'] = frame_time\n",
    "                    \n",
    "                feature_set = feature_set.append(pd.DataFrame(data=feature, index=[0]))\n",
    "    \n",
    "    return feature_set\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_EDA = '/Users/gioelepozzi/Desktop/MasterThesis/code/eda_feature_extraction/data'\n",
    "path_VA = '/Users/gioelepozzi/Desktop/data/annotations'\n",
    "\n",
    "a = extract_dynamic_features(path_EDA, path_VA, 50, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     \n",
    "# get the directory\n",
    "path_EDA = '/Users/gioelepozzi/Desktop/MasterThesis/code/eda_feature_extraction/data'\n",
    "path_VA = '/Users/gioelepozzi/Desktop/data/annotations'\n",
    "\n",
    "l = [] # lista per unire i risultati in un DataFrame unico\n",
    "count = 1 # contatore per ciclare tutti i brani nel file con i dati di VA\n",
    "dictionary = {} # per creare il DataFrame\n",
    "\n",
    "# ciclo per ogni brano\n",
    "for csv_file in tqdm(natsorted(os.listdir(path_EDA))):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        # prendo dal nome del file il numero del brano (music_ID)\n",
    "        file_name = os.path.basename(csv_file)\n",
    "        music_ID = file_name.split('_')[0]\n",
    "        #print('file name',file_name,music_ID, VA_std.iloc[count][0])\n",
    "\n",
    "        \n",
    "        # prendo file con valori di EDA e VA\n",
    "        my_data = pd.read_csv(path_EDA + '/' + file_name, header = None)\n",
    "        VA_std = pd.read_csv(path_VA + '/static_annotations_std.csv', header = None)\n",
    "        VA_mean = pd.read_csv(path_VA + '/static_annotations.csv', header = None)\n",
    "        \n",
    "        # ci sono alcuni file EDA che non hanno il corrispettivo valore di VA\n",
    "        if music_ID != VA_std.iloc[count][0]:\n",
    "            continue\n",
    "\n",
    "        # prendo valori di VA dai file qua sopra\n",
    "        v_std = VA_std.iloc[count][2]\n",
    "        a_std = VA_std.iloc[count][1]\n",
    "        v_mean = VA_mean.iloc[count][2]\n",
    "        a_mean = VA_mean.iloc[count][1]\n",
    "        count = count + 1\n",
    "        \n",
    "        # prendo ID della persona dai file EDA\n",
    "        subject_ID = my_data.loc[0]\n",
    "        \n",
    "        # creo un vettore dei soggetti, per ogni brano. Per ogni soggetto calcolo features\n",
    "        subject_vector = []\n",
    "        \n",
    "        ZCR_vector = []\n",
    "        \n",
    "        for i in range(1,len(subject_ID)):\n",
    "            subject_vector.append(int(subject_ID[i]))\n",
    "            \n",
    "            # modifica del segnale per fare resampling, filtraggio, e prendere la parte di phasic\n",
    "            eda_data = [] # rappresenta la colonna con il segnale nei file EDA, uno per ogni soggetto\n",
    "            s = my_data.iloc[:][i]\n",
    "            for k in range(1, len(s)):\n",
    "                eda_data.append(s[k])\n",
    "                \n",
    "            fs = 50\n",
    "            times = np.arange(len(eda_data))/fs\n",
    "            \n",
    "            # prendo la parte phasic del segnale\n",
    "            phasic = initialize_signal(eda_data, fs = fs, s_type = 'eda')\n",
    "            \n",
    "            window = 50\n",
    "            stride = 25\n",
    "            frames = window_with_overlap(phasic, window, stride)\n",
    "            time_frames = window_with_overlap(times, window, stride)\n",
    "            \n",
    "            for fidx, frame in enumerate(frames):\n",
    "                \n",
    "                frame_time = fidx*0.5+1\n",
    "                times = time_frames[fidx]\n",
    "            \n",
    "            \n",
    "            # creo un dizionario\n",
    "        labels = [\n",
    "            'music_ID',\n",
    "            'subject_ID',\n",
    "            'frame',\n",
    "            'valence(mean)',\n",
    "            'arousal(mean)',\n",
    "            'valence(std)',\n",
    "            'arousal(std)',\n",
    "            'ZCR'\n",
    "        ]\n",
    "        values = [\n",
    "            music_ID,\n",
    "            subject_vector,\n",
    "            frame,\n",
    "            v_mean,\n",
    "            a_mean,\n",
    "            v_std,\n",
    "            a_std,\n",
    "            ZCR_vector\n",
    "        ]\n",
    "        \n",
    "        # popolo il dizionario\n",
    "        for j in range(len(labels)):\n",
    "            dictionary[labels[j]] = values[j]\n",
    "        \n",
    "        # creo il dataframe\n",
    "        df = pd.DataFrame(dictionary)\n",
    "        l.append(df)\n",
    "        \n",
    "        continue\n",
    "\n",
    "\n",
    "results = pd.concat(l, ignore_index=True)\n",
    "\n",
    "\n",
    "# normalizzazione [0,1] per ogni feature, dalla colonna td_mean (7) in poi\n",
    "#for n in range(6,26) :\n",
    "#    if labels[n] == 'ZCR': # per ZCR, non voglio normalizzare questa colonna\n",
    "#        continue\n",
    "#    a = results.iloc[:,n]\n",
    "#    b = (a - np.min(a))/np.ptp(a)\n",
    "#    results.update(b)\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
