{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the dataframe\n",
    "\n",
    "Per ora i file sono organizzati:\n",
    "* i file eda sono nella cartella data scaricabile da PMEmo.\n",
    "* i dati di Valence-Arousal sono nella cartella VA:\n",
    "    * static_annotations_std.csv -> VA in std dev\n",
    "    * static_annotations.csv -> VA in mean\n",
    "    \n",
    "Viene creato un DataFrame con tante righe quanti i soggetti per ogni brano e tante colonne quante features, da time domain features, statistic features.\n",
    "I dati EDA \"raw\" vengono pre-processati nella funzione initialize_signal:\n",
    "* crea il segnale EvenlySignal dalla libreria pyphysio\n",
    "* da la possibilità di fare resampling\n",
    "* da la possibilità di filtrare il segnale per ridurre il rumore\n",
    "* estrae la parte di phasic (SCR)\n",
    "\n",
    "\n",
    "#### Da chiedere:\n",
    "* normalizzazione su ogni colonna nel range [0,1]\n",
    "* rimuovere features poco utili?\n",
    "* calcolo di tutte le features sul phasic, ok?\n",
    "* features dinamiche? si? con window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats, signal\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the EDA signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please cite:\n",
      "Bizzego et al. (2019) 'pyphysio: A physiological signal processing library for data science approaches in physiology', SoftwareX\n"
     ]
    }
   ],
   "source": [
    "import pyphysio as ph\n",
    "import pyphysio.filters.Filters as flt\n",
    "import pyphysio.estimators.Estimators as est\n",
    "import pyphysio.indicators.TimeDomain as td_ind\n",
    "import pyphysio.indicators.FrequencyDomain as fd_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_signal(signal, fs, s_type):\n",
    "    \n",
    "    # creazione di un segnale con una fs fissata\n",
    "    signal = ph.EvenlySignal(values = signal, sampling_freq = fs, signal_type = s_type)\n",
    "    #signal.plot('r')\n",
    "    \n",
    "    # resampling\n",
    "    signal_resampled = signal.resample(fout=32) # fout: sampling frequency for resampling\n",
    "    signal = signal_resampled\n",
    "    #signal.plot('.')\n",
    "    \n",
    "    # filtering\n",
    "    signal_filt = flt.IIRFilter(fp=0.8, fs = 1.1, ftype='ellip')(signal)\n",
    "    signal = signal_filt\n",
    "    #signal.plot('g')\n",
    "    \n",
    "    # phasic extraction\n",
    "    driver = est.DriverEstim()(signal)\n",
    "    phasic, tonic, _ = ph.PhasicEstim(delta=0.02)(driver)\n",
    "    signal = phasic\n",
    "    #phasic.plot('b')\n",
    "    \n",
    "    # min-max normalization [0,1]\n",
    "    #signal_normalized = (phasic - np.min(phasic))/np.ptp(phasic)\n",
    "    #phasic = signal_normalized\n",
    "     \n",
    "    return phasic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time domain\n",
    "\n",
    "def td_mean(signal):\n",
    "    # arithmetic mean of the signal\n",
    "    td_mean = td_ind.Mean() # create the indicator\n",
    "    td_mean_ = td_mean(signal)\n",
    "    #print('mean: ', td_mean_)\n",
    "    return td_mean_\n",
    "\n",
    "def td_min(signal):\n",
    "    td_min = td_ind.Min()\n",
    "    td_min_ = td_min(signal)\n",
    "    #print('min: ', td_min_)\n",
    "    return td_min_\n",
    "\n",
    "def td_max(signal):\n",
    "    td_max = td_ind.Max()\n",
    "    td_max_ = td_max(signal)\n",
    "    #print('max: ', td_max_)\n",
    "    return td_max_\n",
    "\n",
    "def td_range(signal):\n",
    "    td_range = td_ind.Range()\n",
    "    td_range_ = td_range(signal)\n",
    "    #print('range: ', td_range_)\n",
    "    return td_range_\n",
    "\n",
    "def td_median(signal):\n",
    "    td_median = td_ind.Median()\n",
    "    td_median_ = td_median(signal)\n",
    "    #print('median: ', td_median_)\n",
    "    return td_median_\n",
    "\n",
    "def td_std_dev(signal):\n",
    "    td_stdev = td_ind.StDev()\n",
    "    td_stdev_ = td_stdev(signal)\n",
    "    #print('standard deviation: ', td_stdev_)\n",
    "    return td_stdev_\n",
    "\n",
    "def td_sum(signal):\n",
    "    # sum of the values in the signal\n",
    "    td_sum = td_ind.Sum()\n",
    "    td_sum_ = td_sum(signal)\n",
    "    #print('sum: ', td_sum_)\n",
    "    return td_sum_\n",
    "\n",
    "def td_AUC(signal):\n",
    "    # AUC: area under the curve of the signal\n",
    "    td_AUC = td_ind.AUC()\n",
    "    td_AUC_ = td_AUC(signal)\n",
    "    #print('AUC: ', td_AUC_)\n",
    "    return td_AUC_\n",
    "\n",
    "def td_RMSSD(signal):\n",
    "    # RMSSD: square root of the mean of the squared 1st order discrete differences\n",
    "    td_RMSSD = td_ind.RMSSD()\n",
    "    td_RMSSD_ = td_RMSSD(signal)\n",
    "    #print('RMSSD: ', td_RMSSD_)\n",
    "    return td_RMSSD_\n",
    "\n",
    "def td_SDSD(signal):\n",
    "    # SDSD: standard deviation of the 1st order discrete differences\n",
    "    td_SDSD = td_ind.SDSD()\n",
    "    td_SDSD_ = td_SDSD(signal)\n",
    "    #print('SDSD: ', td_SDSD_)\n",
    "    return td_SDSD_\n",
    "\n",
    "\n",
    "# frequency domain\n",
    "\n",
    "def fd_powerinband(signal,f_min, f_max):\n",
    "    # estimation of the power in a given frequency band\n",
    "    fd_powerinband = fd_ind.PowerInBand(interp_freq=4, freq_max=f_max, freq_min=f_min, method = 'fft') # create the indicator\n",
    "    fd_powerinband_ = fd_powerinband(signal.resample(4)) # resampling needed to compute PSD\n",
    "    return fd_powerinband_\n",
    "\n",
    "def fd_peakinband(signal,f_min, f_max):\n",
    "    # estimation of the peak frequency in a given frequency band\n",
    "    fd_peakinband = fd_ind.PeakInBand(interp_freq=4, freq_max=f_max, freq_min=f_min, method = 'fft') # create the indicator\n",
    "    fd_peakinband_ = fd_peakinband(phasic.resample(4)) # resampling needed to compute PSD\n",
    "    return fd_peakinband_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation (static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 710/795 [03:23<00:25,  3.30it/s]"
     ]
    }
   ],
   "source": [
    "# get the directory\n",
    "path_EDA = '/Users/gioelepozzi/Desktop/data/EDA'\n",
    "path_VA = '/Users/gioelepozzi/Desktop/data/annotations'\n",
    "\n",
    "l = [] # lista per unire i risultati in un DataFrame unico\n",
    "count = 1 # contatore per ciclare tutti i brani nel file con i dati di VA\n",
    "dictionary = {} # per creare il DataFrame\n",
    "\n",
    "# ciclo per ogni brano\n",
    "for csv_file in tqdm(natsorted(os.listdir(path_EDA))):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        # prendo dal nome del file il numero del brano (music_ID)\n",
    "        file_name = os.path.basename(csv_file)\n",
    "        music_ID = file_name.split('_')[0]\n",
    "        #print('file name',file_name,music_ID, VA_std.iloc[count][0])\n",
    "\n",
    "        \n",
    "        # prendo file con valori di EDA e VA\n",
    "        my_data = pd.read_csv(path_EDA + '/' + file_name, header = None)\n",
    "        VA_std = pd.read_csv(path_VA + '/static_annotations_std.csv', header = None)\n",
    "        VA_mean = pd.read_csv(path_VA + '/static_annotations.csv', header = None)\n",
    "        \n",
    "        # ci sono alcuni file EDA che non hanno il corrispettivo valore di VA\n",
    "        # perchè per validare i valori di VA hanno rifatto ascoltare un brano e se davano valori di VA\n",
    "        # diversi di più di 0.25 venivano scartati\n",
    "        if music_ID != VA_std.iloc[count][0]:\n",
    "            continue\n",
    "\n",
    "        # prendo valori di VA dai file qua sopra\n",
    "        v_std = VA_std.iloc[count][2]\n",
    "        a_std = VA_std.iloc[count][1]\n",
    "        v_mean = VA_mean.iloc[count][2]\n",
    "        a_mean = VA_mean.iloc[count][1]\n",
    "        count = count + 1\n",
    "        \n",
    "        # prendo ID della persona dai file EDA\n",
    "        subject_ID = my_data.loc[0]\n",
    "        \n",
    "        # creo un vettore dei soggetti, per ogni brano. Per ogni soggetto calcolo features\n",
    "        subject_vector = []\n",
    "        td_mean_vector = []\n",
    "        td_std_vector = []\n",
    "        td_kurt_vector = []\n",
    "        td_skew_vector = []\n",
    "        psd_vector = []\n",
    "        td_mean_vector = []\n",
    "        td_min_vector = []\n",
    "        td_max_vector = []\n",
    "        td_range_vector = []\n",
    "        td_median_vector = []\n",
    "        td_std_dev_vector = []\n",
    "        td_sum_vector = []\n",
    "        td_AUC_vector = []\n",
    "        td_RMSSD_vector = []\n",
    "        td_SDSD_vector = []\n",
    "        \n",
    "        ZCR_vector = []\n",
    "        \n",
    "        fd_mean_vector = []\n",
    "        fd_std_vector = []\n",
    "        fd_kurt_vector = []\n",
    "        fd_skew_vector = []\n",
    "        fd_min_vector = []\n",
    "        fd_max_vector = []\n",
    "        fd_range_vector = []\n",
    "        \n",
    "        fd_powerinband_vector1 = []\n",
    "        fd_powerinband_vector2 = []\n",
    "        fd_powerinband_vector3 = []\n",
    "        fd_powerinband_vector4 = []\n",
    "        fd_powerinband_vector5 = []\n",
    "        \n",
    "        fd_peakinband_vector1 = []\n",
    "        fd_peakinband_vector2 = []\n",
    "        fd_peakinband_vector3 = []\n",
    "        fd_peakinband_vector4 = []\n",
    "        fd_peakinband_vector5 = []\n",
    "\n",
    "        \n",
    "        for i in range(1,len(subject_ID)):\n",
    "            subject_vector.append(int(subject_ID[i]))\n",
    "            \n",
    "            # modifica del segnale per fare resampling, filtraggio, e prendere la parte di phasic\n",
    "            eda_data = [] # rappresenta la colonna con il segnale nei file EDA, uno per ogni soggetto\n",
    "            s = my_data.iloc[:][i]\n",
    "            for k in range(1, len(s)):\n",
    "                eda_data.append(s[k])\n",
    "                \n",
    "            fs = 50\n",
    "            times = np.arange(len(eda_data))/fs\n",
    "            \n",
    "            # prendo la parte phasic del segnale\n",
    "            phasic = initialize_signal(eda_data, fs = 50, s_type = 'eda')\n",
    "            \n",
    "            frequency_signal = np.abs(np.fft.fft(phasic))\n",
    "            frequency = np.fft.fftfreq(phasic.size, d=1/fs)\n",
    "            \n",
    "            # funzioni statistiche nel tempo\n",
    "            td_mean_vector.append(np.mean(phasic))\n",
    "            td_std_vector.append(np.std(phasic))\n",
    "            td_kurt_vector.append(stats.kurtosis(phasic))\n",
    "            td_skew_vector.append(stats.skew(phasic))\n",
    "            psd_vector.append(signal.periodogram(phasic))\n",
    "            \n",
    "            # richiamo delle funzioni che calcolano le features e metto in un vettore\n",
    "            td_min_vector.append(td_min(phasic))\n",
    "            td_max_vector.append(td_max(phasic))\n",
    "            td_range_vector.append(td_range(phasic))\n",
    "            td_median_vector.append(td_median(phasic))\n",
    "            td_sum_vector.append(td_sum(phasic))\n",
    "            td_AUC_vector.append(td_AUC(phasic))\n",
    "            td_RMSSD_vector.append(td_RMSSD(phasic))\n",
    "            td_SDSD_vector.append(td_SDSD(phasic))\n",
    "            \n",
    "            ZCR_vector.append(((phasic[:-1] * phasic[1:]) < 0).sum())\n",
    "            \n",
    "            fd_mean_vector.append(np.mean(frequency_signal))\n",
    "            fd_std_vector.append(np.std(frequency_signal))\n",
    "            fd_kurt_vector.append(stats.kurtosis(frequency_signal))\n",
    "            fd_skew_vector.append(stats.skew(frequency_signal))\n",
    "            fd_min_vector.append(frequency_signal.min())\n",
    "            fd_max_vector.append(frequency_signal.max())\n",
    "            fd_range_vector.append(frequency_signal.max()-frequency_signal.min())\n",
    "            \n",
    "            # 0-0.1-0.2-0.3-0.4-0.5 come in PMEmo\n",
    "            fd_powerinband_vector1.append(fd_powerinband(phasic,0,0.1))\n",
    "            fd_powerinband_vector2.append(fd_powerinband(phasic,0.1,0.2))\n",
    "            fd_powerinband_vector3.append(fd_powerinband(phasic,0.2,0.3))\n",
    "            fd_powerinband_vector4.append(fd_powerinband(phasic,0.3,0.4))\n",
    "            fd_powerinband_vector5.append(fd_powerinband(phasic,0.4,0.5))\n",
    "            \n",
    "            fd_peakinband_vector1.append(fd_peakinband(phasic,0,0.1))\n",
    "            fd_peakinband_vector2.append(fd_peakinband(phasic,0.1,0.2))\n",
    "            fd_peakinband_vector3.append(fd_peakinband(phasic,0.2,0.3))\n",
    "            fd_peakinband_vector4.append(fd_peakinband(phasic,0.3,0.4))\n",
    "            fd_peakinband_vector5.append(fd_peakinband(phasic,0.4,0.5))\n",
    "            \n",
    "            #print('min vector ', td_min_vector, '\\n\\n')\n",
    "            \n",
    "            #np.seterr(divide='ignore', invalid='ignore')\n",
    "            #td_min_vector_norm = (td_min_vector - np.min(td_min_vector))/np.ptp(td_min_vector)\n",
    "            \n",
    "            \n",
    "        # creo un dizionario\n",
    "        labels = [\n",
    "            'music_ID',\n",
    "            'subject_ID',\n",
    "            'valence(mean)',\n",
    "            'arousal(mean)',\n",
    "            'valence(std)',\n",
    "            'arousal(std)',\n",
    "            'td_mean',\n",
    "            'td_std',\n",
    "            'td_kurt',\n",
    "            'td_skew',\n",
    "            'td_min',\n",
    "            'td_max',\n",
    "            'td_range',\n",
    "            'td_median',\n",
    "            'td_sum',\n",
    "            'td_AUC',\n",
    "            'td_RMSSD',\n",
    "            'td_SDSD',\n",
    "            'ZCR',\n",
    "            'fd_mean',\n",
    "            'fd_std',\n",
    "            'fd_kurt',\n",
    "            'fd_skew',\n",
    "            'fd_min',\n",
    "            'fd_max',\n",
    "            'fd_range',\n",
    "            'fd_powerinband1',\n",
    "            'fd_powerinband2',\n",
    "            'fd_powerinband3',\n",
    "            'fd_powerinband4',\n",
    "            'fd_powerinband5',\n",
    "            'fd_peakinband1',\n",
    "            'fd_peakinband2',\n",
    "            'fd_peakinband3',\n",
    "            'fd_peakinband4',\n",
    "            'fd_peakinband5'\n",
    "        ]\n",
    "        values = [\n",
    "            music_ID,\n",
    "            subject_vector,\n",
    "            v_mean,\n",
    "            a_mean,\n",
    "            v_std,\n",
    "            a_std,\n",
    "            td_mean_vector,\n",
    "            td_std_vector,\n",
    "            td_kurt_vector,\n",
    "            td_skew_vector,\n",
    "            td_min_vector,\n",
    "            td_max_vector,\n",
    "            td_range_vector,\n",
    "            td_median_vector,\n",
    "            td_sum_vector,\n",
    "            td_AUC_vector,\n",
    "            td_RMSSD_vector,\n",
    "            td_SDSD_vector,\n",
    "            ZCR_vector,\n",
    "            fd_mean_vector,\n",
    "            fd_std_vector,\n",
    "            fd_kurt_vector,\n",
    "            fd_skew_vector,\n",
    "            fd_min_vector,\n",
    "            fd_max_vector,\n",
    "            fd_range_vector,\n",
    "            fd_powerinband_vector1,\n",
    "            fd_powerinband_vector2,\n",
    "            fd_powerinband_vector3,\n",
    "            fd_powerinband_vector4,\n",
    "            fd_powerinband_vector5,\n",
    "            fd_peakinband_vector1,\n",
    "            fd_peakinband_vector2,\n",
    "            fd_peakinband_vector3,\n",
    "            fd_peakinband_vector4,\n",
    "            fd_peakinband_vector5\n",
    "        ]\n",
    "        \n",
    "        # popolo il dizionario\n",
    "        for j in range(len(labels)):\n",
    "            dictionary[labels[j]] = values[j]\n",
    "        \n",
    "        # creo il dataframe\n",
    "        df = pd.DataFrame(dictionary)\n",
    "        l.append(df)\n",
    "        \n",
    "        continue\n",
    "\n",
    "\n",
    "results = pd.concat(l, ignore_index=True)\n",
    "\n",
    "\n",
    "# normalizzazione [0,1] per ogni feature, dalla colonna td_mean (7) in poi\n",
    "for n in range(6,len(df.columns)) :\n",
    "    if labels[n] == 'ZCR': # per ZCR, non voglio normalizzare questa colonna\n",
    "        continue\n",
    "    a = results.iloc[:,n]\n",
    "    b = (a - np.min(a))/np.ptp(a)\n",
    "    results.update(b)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Static features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_EDA_static_features(path_EDA, path_VA):\n",
    "    \n",
    "    feature_set = pd.DataFrame()\n",
    "    count = 1\n",
    "    \n",
    "    # for every .mp3 file get a set of features\n",
    "    for csv_file in tqdm(natsorted(os.listdir(path_EDA))):\n",
    "        if csv_file.endswith(\".csv\"):\n",
    "    \n",
    "            file_name = os.path.basename(csv_file)\n",
    "            id = file_name.split('_')[0] # music_ID\n",
    "            data = pd.read_csv(path_EDA + '/' + file_name, header = None)\n",
    "            VA_std = pd.read_csv(path_VA + '/static_annotations_std.csv', header = None)\n",
    "            VA_mean = pd.read_csv(path_VA + '/static_annotations.csv', header = None)\n",
    "        \n",
    "            # There are some EDA files with no VA data, so exclude them\n",
    "            # due to data validation, see PMEmo paper for more details\n",
    "            if id != VA_std.iloc[count][0]:\n",
    "                continue\n",
    "\n",
    "            # save VA values for EDA file\n",
    "            v_std = VA_std.iloc[count][2]\n",
    "            a_std = VA_std.iloc[count][1]\n",
    "            v_mean = VA_mean.iloc[count][2]\n",
    "            a_mean = VA_mean.iloc[count][1]\n",
    "            count = count + 1\n",
    "            \n",
    "            feature = {}\n",
    "\n",
    "            # cicle over all the subjects in one EDA file\n",
    "            for i in range(1,len(data.loc[0])):\n",
    "                \n",
    "                subject_ID = data.iloc[0][i]\n",
    "                \n",
    "                s = data.iloc[:][i].to_numpy()\n",
    "                eda_data = np.delete(s,[0])\n",
    "\n",
    "                #### estrarre features, da np array eda_data\n",
    "                \n",
    "                # modifica del segnale per fare resampling, filtraggio, e prendere la parte di phasic\n",
    "                fs = 50\n",
    "            \n",
    "                phasic = initialize_signal(eda_data, fs = fs, s_type = 'eda')\n",
    "                td_mean = np.mean(phasic)\n",
    "                \n",
    "                \n",
    "                feature['music_ID'] = id\n",
    "                feature['subject_ID'] = int(subject_ID)\n",
    "                feature['td_mean'] = td_mean\n",
    "            \n",
    "                feature_set = feature_set.append(pd.DataFrame(data=feature, index=[0]))\n",
    "            \n",
    "    return feature_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  9.39it/s]\n"
     ]
    }
   ],
   "source": [
    "path_EDA = '/Users/gioelepozzi/Desktop/MasterThesis/code/eda_feature_extraction/data'\n",
    "\n",
    "path_VA = '/Users/gioelepozzi/Desktop/data/annotations'\n",
    "\n",
    "static = extract_EDA_static_features(path_EDA, path_VA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music_ID</th>\n",
       "      <th>subject_ID</th>\n",
       "      <th>td_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100179</td>\n",
       "      <td>2.871903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100184</td>\n",
       "      <td>0.510666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100180</td>\n",
       "      <td>0.028471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110448</td>\n",
       "      <td>0.601928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100178</td>\n",
       "      <td>0.009695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>200373</td>\n",
       "      <td>-0.059312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100181</td>\n",
       "      <td>1.447602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100435</td>\n",
       "      <td>0.002033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100443</td>\n",
       "      <td>0.797665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100177</td>\n",
       "      <td>1.416402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>200384</td>\n",
       "      <td>0.406086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100259</td>\n",
       "      <td>0.173612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100264</td>\n",
       "      <td>0.816979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100266</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>110430</td>\n",
       "      <td>0.577375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100262</td>\n",
       "      <td>0.014284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100260</td>\n",
       "      <td>0.550693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100265</td>\n",
       "      <td>0.205768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100261</td>\n",
       "      <td>0.158570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100263</td>\n",
       "      <td>0.636244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100211</td>\n",
       "      <td>0.021954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100213</td>\n",
       "      <td>0.007091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100217</td>\n",
       "      <td>0.040635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100215</td>\n",
       "      <td>0.012701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100212</td>\n",
       "      <td>0.686559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100210</td>\n",
       "      <td>0.519718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100214</td>\n",
       "      <td>0.025445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100216</td>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>110416</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>200377</td>\n",
       "      <td>0.954640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  music_ID  subject_ID   td_mean\n",
       "0        1      100179  2.871903\n",
       "0        1      100184  0.510666\n",
       "0        1      100180  0.028471\n",
       "0        1      110448  0.601928\n",
       "0        1      100178  0.009695\n",
       "0        1      200373 -0.059312\n",
       "0        1      100181  1.447602\n",
       "0        1      100435  0.002033\n",
       "0        1      100443  0.797665\n",
       "0        1      100177  1.416402\n",
       "0        4      200384  0.406086\n",
       "0        4      100259  0.173612\n",
       "0        4      100264  0.816979\n",
       "0        4      100266  0.008214\n",
       "0        4      110430  0.577375\n",
       "0        4      100262  0.014284\n",
       "0        4      100260  0.550693\n",
       "0        4      100265  0.205768\n",
       "0        4      100261  0.158570\n",
       "0        4      100263  0.636244\n",
       "0        5      100211  0.021954\n",
       "0        5      100213  0.007091\n",
       "0        5      100217  0.040635\n",
       "0        5      100215  0.012701\n",
       "0        5      100212  0.686559\n",
       "0        5      100210  0.519718\n",
       "0        5      100214  0.025445\n",
       "0        5      100216  0.002516\n",
       "0        5      110416  0.005488\n",
       "0        5      200377  0.954640"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results\n",
    "\n",
    "static.to_csv('static_features_EDA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_with_overlap(a, window, stride):\n",
    "    nrows = ((a.size-window)//stride)+1 # // floor division\n",
    "    n = a.strides[0]\n",
    "    # create a view into the array a with the given shape and strides\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=(nrows,window), strides=(stride*n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dynamic_features(path_EDA, path_VA, window, stride):\n",
    "    \n",
    "    feature_set = pd.DataFrame()\n",
    "    count = 1\n",
    "    \n",
    "    for eda_file in tqdm(natsorted(os.listdir(path_EDA))):\n",
    "        if eda_file.endswith('.csv'):\n",
    "            \n",
    "            file_name = os.path.basename(eda_file)\n",
    "            id = file_name.split('_')[0]\n",
    "            data = pd.read_csv(path_EDA + '/' + file_name, header = None)\n",
    "            VA_std = pd.read_csv(path_VA + '/static_annotations_std.csv', header = None)\n",
    "            VA_mean = pd.read_csv(path_VA + '/static_annotations.csv', header = None)\n",
    "            \n",
    "            subject_vector = []\n",
    "            \n",
    "            if id!= VA_std.iloc[count][0]:\n",
    "                continue\n",
    "            \n",
    "            v_std = VA_std.iloc[count][2]\n",
    "            a_std = VA_std.iloc[count][1]\n",
    "            v_mean = VA_mean.iloc[count][2]\n",
    "            a_mean = VA_mean.iloc[count][1]\n",
    "            count = count + 1\n",
    "            subject_ID = data.loc[0]\n",
    "            \n",
    "            for i in range(1,len(subject_ID)):\n",
    "                subject_vector.append(int(subject_ID[i]))\n",
    "                eda_data = [] # rappresenta la colonna con il segnale nei file EDA, uno per ogni soggetto\n",
    "                s = my_data.iloc[:][i]\n",
    "                for k in range(1, len(s)):\n",
    "                    eda_data.append(s[k])\n",
    "                \n",
    "                sr = 50\n",
    "                times = np.arange(len(eda_data))/sr\n",
    "                phasic = initialize_signal(eda_data, fs = sr, s_type = 'eda')\n",
    "                \n",
    "                times = np.arange(len(phasic))/sr\n",
    "                frames = window_with_overlap(phasic, window, stride)\n",
    "                time_frames = window_with_overlap(times, window, stride)\n",
    "                \n",
    "                for fidx, frame in enumerate(frames):\n",
    "                    \n",
    "                    feature = {}\n",
    "                    frame_time = fidx*0.5+1\n",
    "                    times = time_frames[fidx]\n",
    "                    frequency_signal = np.abs(np.fft.fft(frame))\n",
    "                    frequency = np.fft.fftfreq(frame.size, d=1/sr)\n",
    "                                        \n",
    "                    #print(fidx, frame_time, subject_ID)\n",
    "\n",
    "\n",
    "                    feature['music_ID'] = id\n",
    "                    feature['subject_ID'] = subject_ID\n",
    "                    feature['frame_time'] = frame_time\n",
    "                    \n",
    "                feature_set = feature_set.append(pd.DataFrame(data=feature, index=[0]))\n",
    "    \n",
    "    return feature_set\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "path_EDA = '/Users/gioelepozzi/Desktop/MasterThesis/code/eda_feature_extraction/data'\n",
    "path_VA = '/Users/gioelepozzi/Desktop/data/annotations'\n",
    "\n",
    "a = extract_dynamic_features(path_EDA, path_VA, 50, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-62a5d1f79633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# creo il dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         ]\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "\n",
    "     \n",
    "# get the directory\n",
    "path_EDA = '/Users/gioelepozzi/Desktop/MasterThesis/code/eda_feature_extraction/data'\n",
    "path_VA = '/Users/gioelepozzi/Desktop/data/annotations'\n",
    "\n",
    "l = [] # lista per unire i risultati in un DataFrame unico\n",
    "count = 1 # contatore per ciclare tutti i brani nel file con i dati di VA\n",
    "dictionary = {} # per creare il DataFrame\n",
    "\n",
    "# ciclo per ogni brano\n",
    "for csv_file in tqdm(natsorted(os.listdir(path_EDA))):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        # prendo dal nome del file il numero del brano (music_ID)\n",
    "        file_name = os.path.basename(csv_file)\n",
    "        music_ID = file_name.split('_')[0]\n",
    "        #print('file name',file_name,music_ID, VA_std.iloc[count][0])\n",
    "\n",
    "        \n",
    "        # prendo file con valori di EDA e VA\n",
    "        my_data = pd.read_csv(path_EDA + '/' + file_name, header = None)\n",
    "        VA_std = pd.read_csv(path_VA + '/static_annotations_std.csv', header = None)\n",
    "        VA_mean = pd.read_csv(path_VA + '/static_annotations.csv', header = None)\n",
    "        \n",
    "        # ci sono alcuni file EDA che non hanno il corrispettivo valore di VA\n",
    "        if music_ID != VA_std.iloc[count][0]:\n",
    "            continue\n",
    "\n",
    "        # prendo valori di VA dai file qua sopra\n",
    "        v_std = VA_std.iloc[count][2]\n",
    "        a_std = VA_std.iloc[count][1]\n",
    "        v_mean = VA_mean.iloc[count][2]\n",
    "        a_mean = VA_mean.iloc[count][1]\n",
    "        count = count + 1\n",
    "        \n",
    "        # prendo ID della persona dai file EDA\n",
    "        subject_ID = my_data.loc[0]\n",
    "        \n",
    "        # creo un vettore dei soggetti, per ogni brano. Per ogni soggetto calcolo features\n",
    "        subject_vector = []\n",
    "        \n",
    "        ZCR_vector = []\n",
    "        \n",
    "        for i in range(1,len(subject_ID)):\n",
    "            subject_vector.append(int(subject_ID[i]))\n",
    "            \n",
    "            # modifica del segnale per fare resampling, filtraggio, e prendere la parte di phasic\n",
    "            eda_data = [] # rappresenta la colonna con il segnale nei file EDA, uno per ogni soggetto\n",
    "            s = my_data.iloc[:][i]\n",
    "            for k in range(1, len(s)):\n",
    "                eda_data.append(s[k])\n",
    "                \n",
    "            fs = 50\n",
    "            times = np.arange(len(eda_data))/fs\n",
    "            \n",
    "            # prendo la parte phasic del segnale\n",
    "            phasic = initialize_signal(eda_data, fs = fs, s_type = 'eda')\n",
    "            \n",
    "            window = 50\n",
    "            stride = 25\n",
    "            frames = window_with_overlap(phasic, window, stride)\n",
    "            time_frames = window_with_overlap(times, window, stride)\n",
    "            \n",
    "            for fidx, frame in enumerate(frames):\n",
    "                \n",
    "                frame_time = fidx*0.5+1\n",
    "                times = time_frames[fidx]\n",
    "            \n",
    "            \n",
    "            # creo un dizionario\n",
    "        labels = [\n",
    "            'music_ID',\n",
    "            'subject_ID',\n",
    "            'frame',\n",
    "            'valence(mean)',\n",
    "            'arousal(mean)',\n",
    "            'valence(std)',\n",
    "            'arousal(std)',\n",
    "            'ZCR'\n",
    "        ]\n",
    "        values = [\n",
    "            music_ID,\n",
    "            subject_vector,\n",
    "            frame,\n",
    "            v_mean,\n",
    "            a_mean,\n",
    "            v_std,\n",
    "            a_std,\n",
    "            ZCR_vector\n",
    "        ]\n",
    "        \n",
    "        # popolo il dizionario\n",
    "        for j in range(len(labels)):\n",
    "            dictionary[labels[j]] = values[j]\n",
    "        \n",
    "        # creo il dataframe\n",
    "        df = pd.DataFrame(dictionary)\n",
    "        l.append(df)\n",
    "        \n",
    "        continue\n",
    "\n",
    "\n",
    "results = pd.concat(l, ignore_index=True)\n",
    "\n",
    "\n",
    "# normalizzazione [0,1] per ogni feature, dalla colonna td_mean (7) in poi\n",
    "#for n in range(6,26) :\n",
    "#    if labels[n] == 'ZCR': # per ZCR, non voglio normalizzare questa colonna\n",
    "#        continue\n",
    "#    a = results.iloc[:,n]\n",
    "#    b = (a - np.min(a))/np.ptp(a)\n",
    "#    results.update(b)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
