@book{Suzuki2011,
abstract = {This paper summarizes my 40 years of research on speech and speaker recognition, focusing on selected topics that I have investigated at NTT Laboratories, Bell Laboratories and Tokyo Institute of Technology with my colleagues and students. These topics include: the importance of spectral dynamics in speech perception; speaker recognition methods using statistical features, cepstral features, and HMM/GMM; text-prompted speaker recognition; speech recognition using dynamic features; Japanese LVCSR; robust speech recognition; spontaneous speech corpus construction and analysis; spontaneous speech recognition; automatic speech summarization; and WFST-based decoder development and its applications.},
address = {Singapore, SG},
author = {Suzuki, Yoiti and Brungart, D and Kato, H and Iida, K and Suzuku, Y},
booktitle = {Recherche},
doi = {10.1142/7674},
edition = {1st},
file = {:media/francesco/Data/Mega/Mendeley/Suzuki et al. - 2011 - Principles and Applications of Spatial Hearing.pdf:pdf},
isbn = {9789814299312},
publisher = {World Scientific},
title = {{Principles and Applications of Spatial Hearing}},
url = {http://www.amazon.com/Principles-Applications-Spatial-Hearing-Suzuki/dp/9814313874},
year = {2011}
}
@book{Saleh1991,
address = {New York, NY, USA},
author = {Saleh, Bahaa E. A. and Teich, Malvin Carl},
doi = {10.1002/0471213748},
editor = {Goodman, J. W.},
isbn = {9780471213741},
publisher = {Wiley {\&} Sons, Inc.},
title = {{Fundamentals of Photonics}},
year = {1991}
}
@techreport{AES2008,
abstract = {This standard describes how the measurements of loudspeaker polar radiation data shall be made and documented. This acquired data is suitable for application in room acoustic, electro-acoustic, and sound system predictions, and loudspeaker data sheets.},
address = {New York, NY, USA},
booktitle = {AES Stand.},
file = {:media/francesco/Data/Mega/Mendeley/Unknown - 2008 - AES Standards on Acoustics - Sound Source Modeling - Loudspeaker Polar Radiation Measurements.pdf:pdf},
number = {Reaffirmed},
publisher = {Audio Engineering Society},
title = {{AES Standards on Acoustics - Sound Source Modeling - Loudspeaker Polar Radiation Measurements}},
volume = {2014},
year = {2008}
}
@inproceedings{Talagala2013,
abstract = {The equalization of reverberation effects is essential for spatial soundfield reproduction, but estimation of the reverberant channel presents several challenges to existing equalization techniques. This paper presents a method of active acoustic echo cancellation (AEC) for soundfield reproduction applications, using a modal description of the reverberant soundfield. We describe how individual modes of the measured soundfield can be equalized adaptively, thus reducing the complexity of the channel estimation process. AEC and reproduction performance is compared with existing adaptive and non-adaptive equalization techniques through simulation examples. Equalization performance is comparable to existing methods, achieving a normalized region reproduction error of 1{\%} and echo return loss enhancement of 15 - 30 dB at 50 dB SNR. The results suggest that the proposed model can be used to obtain a parallel implementation of a room equalizer for active AEC.},
address = {Vancouver, BC, CA},
author = {Talagala, Dumidu S. and Zhang, Wen and Abhayapala, Thushara D.},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
file = {:media/francesco/Data/Mega/Mendeley/Talagala, Zhang, Abhayapala - 2013 - Active Acoustic Echo Cancellation in Spatial Soundfield Reproduction.pdf:pdf},
isbn = {9781479903566},
keywords = {Acoustic echo cancellation,reverberation,room equalization,soundfield reproduction,spatial filtering},
pages = {620--624},
publisher = {IEEE},
title = {{Active Acoustic Echo Cancellation in Spatial Soundfield Reproduction}},
url = {http://ieeexplore.ieee.org/document/6637722/},
year = {2013}
}
@inproceedings{Tohyama1989,
abstract = {Sound power output from a source can be reduced in a closed space by using secondary sources. The minimum power response (MPR) from sound sources is analyzed based on the modal theory. It is shown that the MPR can be approximately described using the modal overlap properties. The power reduction is confirmed experimentally for a pure tone source in a large reverberation room. The corner method for sensor location is also discussed.},
address = {Glasgow, UK},
author = {Tohyama, Mikio and Suzuki, Akira and Sugiyama, Kiyoshi},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
doi = {https://doi.org/10.1109/ICASSP.1989.266860},
file = {:media/francesco/Data/Mega/Mendeley/Tohyama, Suzuki, Sugiyama - 1989 - Active Power Minimization of a Sound Source in a Reverberant Space.pdf:pdf},
pages = {2037--2040},
publisher = {IEEE},
title = {{Active Power Minimization of a Sound Source in a Reverberant Space}},
year = {1989}
}
@article{Pulkki2007,
abstract = {Directional audio coding (DirAC) is a method for spatial sound representation, applicable for different sound reproduction systems. In the analysis part the diffuseness and direction of arrival of sound are estimated in a single location depending on time and frequency. In the synthesis part microphone signals are first divided into nondiffuse and diffuse parts, and are then reproduced using different strategies. DirAC is developed from an existing technology for impulse response reproduction, spatial impulse response rendering (SIRR), and imple- mentations of DirAC for different applications are described.},
author = {Pulkki, Ville},
file = {:media/francesco/Data/Mega/Mendeley/Pulkki - 2007 - Spatial sound reproduction with directional audio coding.pdf:pdf},
issn = {0004-7554},
journal = {J. Audio Eng. Soc.},
number = {6},
pages = {503--516},
pmid = {34447274778},
title = {{Spatial sound reproduction with directional audio coding}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=14170},
volume = {55},
year = {2007}
}
@inproceedings{Goodwin2008,
abstract = {This paper provides an overview of a framework for generalized multichannel audio processing. In this Spatial Audio Scene Coding (SASC) framework, the central idea is to represent an input audio scene in a way that is independent of any assumed or intended reproduction format. This format-agnostic parameterization enables optimal reproduction over any given playback system as well as flexible scene modification. The signal analysis and synthesis tools needed for SASC are described, including new approaches for multichannel primary-ambient decomposition. Applications of SASC to spatial audio coding, matrix encode-decode, upmix, multichannel format conversion, and binaural reproduction are discussed.},
address = {San Francisco, CA, USA},
author = {{Michael M. Goodwin and Jean-Marc Jot}},
booktitle = {AES 123th Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Michael M. Goodwin and Jean-Marc Jot - 2008 - Spatial Audio Scene Coding.pdf:pdf},
isbn = {9781605607122},
publisher = {Audio Engineering Society},
title = {{Spatial Audio Scene Coding}},
year = {2008}
}
@inproceedings{Johnston2010,
abstract = {For many years, the difference in perception between perceptually direct sounds (i.e., sounds with a specific direction) and perceptually diffuse sounds (i.e., sounds that 'surround' or 'envelop' the listener) have been recognized, leading to a variety of approaches for simulating or capturing these perceptual effects. Here, we discuss a system using separation of direct and diffuse signals, or for synthetic signals (e.g., those made by modern production methods) synthesis of the diffuse signal in one of several ways, in order to enable the reproduction system, after measuring the characteristics of the playback system, to provide the best possible sensation from that particular set of playback equipment.},
address = {San Francisco, CA, USA},
author = {Johnston, James D. and Jot, Jean-Marc and Fejzo, Zoran and Hastings, Steve R.},
booktitle = {AES 129th Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Johnston et al. - 2010 - Beyond Coding Reproduction of Direct and Diffuse Sounds in Multiple Environments.pdf:pdf},
isbn = {9781617821943},
publisher = {Audio Engineering Society},
title = {{Beyond Coding: Reproduction of Direct and Diffuse Sounds in Multiple Environments}},
year = {2010}
}
@article{Avni2013,
abstract = {The area of sound field synthesis has significantly advanced in the past decade, facilitated by the development of high-quality sound-field capturing and re-synthesis systems. Spherical microphone arrays are among the most recently developed systems for sound field capturing, enabling processing and analysis of three-dimensional sound fields in the spherical harmonics domain. In spite of these developments, a clear relation between sound fields recorded by spherical microphone arrays and their perception with a re-synthesis system has not yet been established, although some relation to scalar measures of spatial perception was recently presented. This paper presents an experimental study of spatial sound perception with the use of a spherical microphone array for sound recording and headphone-based binaural sound synthesis. Sound field analysis and processing is performed in the spherical harmonics domain with the use of head-related transfer functions and simulated enclosed sound fields. The effect of several factors, such as spherical harmonics order, frequency bandwidth, and spatial sampling, are investigated by applying the repertory grid technique to the results of the experiment, forming a clearer relation between sound-field capture with a spherical microphone array and its perception using binaural synthesis regarding space, frequency, and additional artifacts. The experimental study clearly shows that a source will be perceived more spatially sharp and more externalized when represented by a binaural stimuli reconstructed with a higher spherical harmonics order. This effect is apparent from low spherical harmonics orders. Spatial aliasing, as a result of sound field capturing with a finite number of microphones, introduces unpleasant artifacts which increased with the degree of aliasing error.},
author = {Avni, Amir and Ahrens, Jens and Geier, Matthias and Spors, Sascha and Wierstorf, Hagen and Rafaely, Boaz},
doi = {10.1121/1.4795780},
file = {:media/francesco/Data/Mega/Mendeley/Avni et al. - 2013 - Spatial perception of sound fields recorded by spherical microphone arrays with varying spatial resolution.pdf:pdf},
isbn = {00014966},
issn = {0001-4966},
journal = {J. Acoust. Soc. Am.},
number = {5},
pages = {2711--2721},
pmid = {23654379},
title = {{Spatial perception of sound fields recorded by spherical microphone arrays with varying spatial resolution}},
volume = {133},
year = {2013}
}
@book{Boyd2010,
abstract = {We are developing a dual panel breast-dedicated PET system using LSO scintillators coupled to position sensitive avalanche photodiodes (PSAPD). The charge output is amplified and read using NOVA RENA-3 ASICs. This paper shows that the coincidence timing resolution of the RENA-3 ASIC can be improved using certain list-mode calibrations. We treat the calibration problem as a convex optimization problem and use the RENA-3s analog-based timing system to correct the measured data for time dispersion effects from correlated noise, PSAPD signal delays and varying signal amplitudes. The direct solution to the optimization problem involves a matrix inversion that grows order (n3) with the number of parameters. An iterative method using single-coordinate descent to approximate the inversion grows order (n). The inversion does not need to run to convergence, since any gains at high iteration number will be low compared to noise amplification. The system calibration method is demonstrated with measured pulser data as well as with two LSO-PSAPD detectors in electronic coincidence. After applying the algorithm, the 511keV photopeak paired coincidence time resolution from the LSO-PSAPD detectors under study improved by 57{\%}, from the raw value of 16.30.07 ns FWHM to 6.920.02 ns FWHM (11.520.05 ns to 4.890.02 ns for unpaired photons).},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Boyd, Stephen P. and Vandenberghe, Lieven},
booktitle = {Optim. Methods Softw.},
doi = {10.1080/10556781003625177},
edition = {1st},
eprint = {1111.6189v1},
file = {:media/francesco/Data/Mega/Mendeley/Boyd, Vandenberghe - 2010 - Convex Optimization.pdf:pdf},
isbn = {9780521833783},
issn = {10556788},
pmid = {20876008},
publisher = {Cambridge University Press},
title = {{Convex Optimization}},
url = {https://web.stanford.edu/{~}boyd/cvxbook/bv{\_}cvxbook.pdf},
year = {2010}
}
@book{Hastie2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
doi = {10.1007/978-0-387-98135-2},
edition = {2nd},
eprint = {arXiv:1011.1669v3},
file = {:media/francesco/Data/Mega/Mendeley/Hastie, Tibshirani, Friedman - 2017 - The Elements of Statistical Learning.pdf:pdf},
isbn = {9781461382447},
issn = {01727397},
pmid = {15772297},
publisher = {Springer},
title = {{The Elements of Statistical Learning}},
year = {2017}
}
@inproceedings{Khalilian2013,
abstract = {We describe a method for approximating a desired sound filed in a cubic region using a planar array of omnidirectional loudspeakers. For this purpose, a constrained matching pursuit algorithm is employed to find the appropriate locations of the loudspeakers. Unlike previously proposed methods for sound field approximation, this iterative procedure attempts to approximate the residual error vector at each iteration, leading to a more efficient representation of the desired field as a linear combination of the Acoustic Transfer Functions (ATFs) of the selected loudspeakers. Simulations suggest that the new method offers considerable improvement in approximation accuracy compared to uniformly placed loudspeakers, as well as another recent method for loudspeaker placement.},
address = {New Paltz, NY, USA},
author = {Khalilian, Hanieh and Bajic, Ivan V. and Vaughan, Rodney G.},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
doi = {10.1109/ICASSP.2013.6637661},
file = {:media/francesco/Data/Mega/Mendeley/Khalilian, Bajic, Vaughan - 2013 - Loudspeaker placement for sound field reproduction by constrained matching pursuit.pdf:pdf},
isbn = {9781479903566},
issn = {15206149},
keywords = {Active sound cancellation,loudspeaker arrays,noise cancellation,sound field reproduction},
number = {2},
pages = {321--325},
publisher = {IEEE},
title = {{Loudspeaker placement for sound field reproduction by constrained matching pursuit}},
year = {2013}
}
@article{Bernardini2017,
abstract = {Performing continuous beam steering, from planar arrays of high-order differential microphones, is not trivial. The main problem is that shape-preserving beams can be steered only in a finite set of privileged directions, which depend on the position and the number of physical microphones. In this letter, we propose a simple and computationally inexpensive method for alleviating this problem using planar microphone arrays. Given two identical reference beams pointing in two different directions, we show how to build a beam of nearly constant shape, which can be continuously steered between such two directions. The proposed method, unlike the diffused steering approaches based on linear combinations of eigenbeams (spherical harmonics), is applicable to planar arrays also if we deal with beams characterized by high-order polar patterns. Using the coefficients of the Fourier series of the polar patterns, we also show how to find a trade-off between shape invariance of the steered beam, and maximum angular displacement between the two reference beams.We show the effectiveness of the proposed method through the analysis of models based on first, second and third-order differential microphones.},
author = {Bernardini, Alberto and D'Aria, Matteo and Sannino, Roberto and Sarti, Augusto},
doi = {10.1109/LSP.2017.2695082},
file = {:media/francesco/Data/Mega/Mendeley/Bernardini et al. - 2017 - Efficient Continuous Beam Steering for Planar Arrays of Differential Microphones(2).pdf:pdf},
issn = {1070-9908},
journal = {IEEE Signal Process. Lett.},
number = {6},
pages = {794--798},
title = {{Efficient Continuous Beam Steering for Planar Arrays of Differential Microphones}},
url = {http://ieeexplore.ieee.org/document/7903573/},
volume = {24},
year = {2017}
}
@inproceedings{Canclini2015a,
abstract = {We propose a method for estimating the 3D radiation pattern of violins, during the performance of amusician. A rectangular array of 32 microphones is adopted for measuring the energy radiated by the violin in the observed directions. In order to gather measurements from all the 3D angular directions, the musician is free to move and rotate in front of the array. The position and orientation of the violin is estimated through a tracking system. As the adopted hardware is very compact and non-invasive, the musician plays in a natural fashion, thus replicating the radiation conditions of a real scenario. The experimental results prove the accuracy and the effectiveness of the method.},
address = {Warsaw, PL},
author = {Canclini, Antonio and Mucci, Luca and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {AES 138th Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Canclini et al. - 2015 - Estimation of the radiation pattern of a violin during the performance using plenacoustic methods.pdf:pdf},
pages = {1--10},
publisher = {Audio Engineering Society},
title = {{Estimation of the radiation pattern of a violin during the performance using plenacoustic methods}},
year = {2015}
}
@inproceedings{Canclini2011,
abstract = {In this paper we propose a methodology for assessing the accuracy of techniques of wave field rendering through loudspeaker arrays. In order to measure the rendered wave field we adopt a solution based on a circular harmonic analysis of the sound field captured by a virtual microphone array. As a result of this analysis stage, we are able to compare the target, the theoretical and the measured wave fields, which may differ due to the non-ideality in the loudspeaker array or in the environment that generates some spurious reverberations. Moreover, in order to quantify the error between target, theoretical and measured wave fields, we define some evaluation metrics, based on RMSE and modal analysis of the acquired wave fields. We show some experimental results on real data.},
address = {Prague, CZ},
author = {Canclini, Antonio and Annibale, Paolo and Antonacci, Fabio and Sarti, Augusto and Rabenstein, Rudolf and Tubaro, Stefano},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
doi = {10.1109/ICASSP.2011.5946330},
file = {:media/francesco/Data/Mega/Mendeley/Canclini et al. - 2011 - A methodology for evaluating the accuracy of wave field rendering techniques.pdf:pdf},
isbn = {9781457705397},
issn = {15206149},
keywords = {Loudspeaker array,virtual microphone array,wave field rendering evaluation},
pages = {69--72},
publisher = {IEEE},
title = {{A methodology for evaluating the accuracy of wave field rendering techniques}},
year = {2011}
}
@article{Betlehem2015,
abstract = {Sound rendering is increasingly being required to extend over certain regions of space for multiple listeners, known as personal sound zones, with minimum interference to listeners in other regions. In this article, we present a systematic overview of the major challenges that have to be dealt with for multizone sound control in a room. Sound control over multiple zones is formulated as an optimization problem, and a unified framework is presented to compare two state-of-the-art sound control techniques. While conventional techniques have been focusing on point-to-point audio processing, we introduce a wave-domain sound field representation and active room compensation for sound pressure control over a region of space. The design of directional loudspeakers is presented and the advantages of using arrays of directional sources are illustrated for sound reproduction, such as better control of sound fields over wide areas and reduced total number of loudspeaker units, thus making it particularly suitable for establishing personal sound zones.},
author = {Betlehem, Terence and Zhang, Wen and Poletti, Mark A. and Abhayapala, Thushara D.},
doi = {10.1109/MSP.2014.2360707},
file = {:media/francesco/Data/Mega/Mendeley/Betlehem et al. - 2015 - Personal sound zones Delivering interface-free audio to multiple listeners.pdf:pdf},
issn = {10535888},
journal = {IEEE Signal Process. Mag.},
number = {2},
pages = {81--91},
title = {{Personal sound zones: Delivering interface-free audio to multiple listeners}},
volume = {32},
year = {2015}
}
@inproceedings{Samarasinghe2013,
abstract = {Three dimensional surround sound reproduction over large areas is a prevailing challenge due to the enormous numbers of loudspeakers required. In this paper, we propose an array of higher order loudspeakers which provide a mode matching solution to the problem based on 3D wavefield translation. It is shown that for a given bandwidth, the use of Lth order sources significantly brings down the minimum loudspeaker requirement by a factor of 1=(L + 1)2. Furthermore, the array is shown to be capable of exterior field cancellation, increasing its performance in echoing environments. Design examples are given for interior field, exterior field and interior and exterior combined field reproduction.},
address = {Vancouver, BC, CA},
author = {Samarasinghe, P. N. and Poletti, Mark A. and Salehin, S. M.A. and Abhayapala, Thushara D. and Fazi, Filippo Maria},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
doi = {10.1109/ICASSP.2013.6637658},
file = {:media/francesco/Data/Mega/Mendeley/Samarasinghe et al. - 2013 - 3D soundfield reproduction using higher order loudspeakers.pdf:pdf},
isbn = {9781479903566},
issn = {15206149},
number = {1},
pages = {306--310},
publisher = {IEEE},
title = {{3D soundfield reproduction using higher order loudspeakers}},
year = {2013}
}
@article{Samarasinghe2015,
abstract = {This paper proposes an efficient parameterization of the room transfer function (RTF). Typically, the RTF rapidly varies with varying source and receiver positions, hence requires an impractical number of point to point measurements to characterize a given room. Therefore, we derive a novel RTF parameterization that is robust to both receiver and source variations with the following salient features: 1) The parameterization is given in terms of a modal expansion of 3D basis functions. 2) The aforementioned modal expansion can be truncated at a finite number of modes given that the source and receiver locations are from two sizeable spatial regions, which are arbitrarily distributed. 3) The parameter weights/coefficients are independent of the source/receiver positions. Therefore, a finite set of coefficients is shown to be capable of accurately calculating the RTF between any two arbitrary points from a pre-defined spatial region where the source(s) lie and a pre-defined spatial region where the receiver(s) lie. A practical method to measure the RTF coefficients is also provided, which only requires a single microphone unit and a single loudspeaker unit, given that the room characteristics remain stationary over time. The accuracy of the above parameterization is verified using appropriate simulation examples. Copyright {\{}{\textcopyright}{\}} 2015 IEEE.},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.04385v1},
author = {Samarasinghe, Prasanga and Abhayapala, Thushara D. and Poletti, Mark A. and Betlehem, Terence},
doi = {10.1109/TASLP.2015.2475173},
eprint = {arXiv:1505.04385v1},
file = {:media/francesco/Data/Mega/Mendeley/Samarasinghe et al. - 2015 - An efficient parameterization of the room transfer function.pdf:pdf},
issn = {15587916},
journal = {IEEE/ACM Trans. Audio, Speech Lang. Process.},
keywords = {Microphone array processing.,Room reverberation,Room transfer function (RTF)},
number = {12},
pages = {2217--2227},
title = {{An efficient parameterization of the room transfer function}},
volume = {23},
year = {2015}
}
@inproceedings{Kuntz2009,
abstract = {A measurement system is presented that allows large aperture measurements with a high angular resolution and that is still compact and thus convenient for portable use. Theoretical considerations show that a cardioid microphone characteristic is desireable to achieve a low amplification of sensor noise throughout the audio frequency range. The directivity of real cardioid microphones, however, deviates from the ideal cardioid pattern. Here, it is demonstrated how the use of one omnidirectional and one figure-of-eight microphone offers the possibility to optimize the directivity pattern of a virtual cardioid microphone through suitably designed compensation filters.},
address = {Espoo, FI},
author = {Kuntz, Achim and Rabenstein, Rudolf},
booktitle = {EAA Symp. Auralization},
file = {:media/francesco/Data/Mega/Mendeley/Kuntz, Rabenstein - 2009 - Cardioid Pattern Optimization for a Virtual Circular Microphone Array.pdf:pdf},
number = {June},
pages = {1--4},
publisher = {EAA},
title = {{Cardioid Pattern Optimization for a Virtual Circular Microphone Array}},
year = {2009}
}
@book{Brandstein2001,
address = {Berlin, Germany},
archivePrefix = {arXiv},
arxivId = {97-80293},
author = {Brandstein, Michael and Ward, Darren B.},
doi = {10.1007/978-3-662-04619-7},
edition = {1st},
editor = {Lacroix, Arild and Venetsanopoulos, Anastasios},
eprint = {97-80293},
file = {:media/francesco/Data/Mega/Mendeley/Brandstein, Ward - 2001 - Microphone Arrays(2).pdf:pdf},
isbn = {978-3-642-07547-6},
issn = {1053-5888},
pages = {398},
pmid = {14213281},
publisher = {Springer},
title = {{Microphone Arrays}},
url = {http://link.springer.com/10.1007/978-3-662-04619-7},
year = {2001}
}
@article{Queen1979,
abstract = {While considerable attention has beenpaid to the effects of room acoustics on the reproduction of wavelengths comparable to room dimensions, little attention has been given to temporal relationships among the loudspeaker, the room, and the listener in listening rooms with volumes under 400 ma. It can be shown that the broadband virtual image created by a 2-channel sound-reproduction system is highly dependent for its clarity on the directional characteristics of the loudspeaker.},
author = {Queen, Daniel},
file = {:media/francesco/Data/Mega/Mendeley/Queen - 1979 - The Effect of Loudspeaker Radiation Patterns on Stereo Imaging and Clarity.pdf:pdf},
issn = {00047554},
journal = {J. Audio Eng. Soc.},
number = {5},
pages = {368--379},
title = {{The Effect of Loudspeaker Radiation Patterns on Stereo Imaging and Clarity}},
volume = {27},
year = {1979}
}
@article{Brungart1999,
abstract = {A series of experiments has examined the auditory localization of a nearby ({\textless} 1 m) sound source under four conditions: (1) a fixed-amplitude condition where loudness-based distance cues were available; (2) a monaural condition where the contralateral ear was occluded by an ear-plug and muff; (3) a high-pass condition where the stimulus bandwidth was 3 Hz to 15 kHz; and (4) a low-pass condition where the stimulus bandwidth was 200 Hz to 3 kHz. The results of these experiments were compared to those of a previous experiment that measured localization performance for a nearby broadband, random-amplitude source [Brungart et al., J. Acoust. Soc. Am. 106, 1956-1968 (1999)]. Directional localization performance in each condition was consistent with the results of previous far-field localization experiments. Distance localization accuracy improved slightly in the fixed-amplitude condition relative to the earlier broadband random-amplitude experiment, especially near the median plane, but was severely degraded in the monaural condition. Distance accuracy was also found to be highly dependent on the low-frequency energy of the stimulus: in the low-pass condition, distance accuracy was similar to that in the broadband condition, while in the high-pass condition, distance accuracy was significantly reduced. The results suggest that low-frequency interaural level differences are the dominant auditory distance cue in the proximal region.},
author = {Brungart, Douglas S.},
doi = {10.1121/1.428212},
file = {:media/francesco/Data/Mega/Mendeley/Brungart - 1999 - Auditory localization of nearby sources. III. Stimulus effects.pdf:pdf},
isbn = {0001-4966 (Print)$\backslash$r0001-4966 (Linking)},
issn = {0001-4966},
journal = {J. Acoust. Soc. Am.},
keywords = {Auditory Perception,Auditory Perception: physiology,Humans,Sound Localization,Sound Localization: physiology},
number = {6},
pages = {3589--3602},
pmid = {10615699},
title = {{Auditory localization of nearby sources. III. Stimulus effects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10615699},
volume = {106},
year = {1999}
}
@article{Poletti2005,
abstract = {The theory of recording and reproduction of three-dimensional sound fields based on spherical harmonics is reviewed and extended. Free-field, sphere, and general recording arrays are reviewed, and the mode-matching and simple source approaches to sound reproduction in anechoic environments are discussed. Both methods avoid the need for both monopole and dipole loudspeakers - as required by the Kirchhoff-Helmholtz integral. An error analysis is presented and simulation examples are given. It is also shown that the theory can be extended to sound reproduction in reverberant environments.},
author = {Poletti, Mark A.},
file = {:media/francesco/Data/Mega/Mendeley/Poletti - 2005 - Three-Dimensional Surround Sound Systems Based on Spherical Harmonics.pdf:pdf},
journal = {J. Audio Eng. Soc.},
number = {11},
pages = {1004--1025},
title = {{Three-Dimensional Surround Sound Systems Based on Spherical Harmonics}},
volume = {53},
year = {2005}
}
@article{Markovic2013,
abstract = {n this work we propose a general approach to acoustic scene analysis based on a novel data structure (ray-space image) that encodes the directional plenacoustic function over a line segment (Observation Window, OW). We define and describe a system for acquiring a ray-space image using a microphone array and refer to it as ray-space (or “soundfield”) camera. The method consists of acquiring the pseudo-spectra corresponding to a grid of sampling points over the OW, and remapping them onto the ray space, which parameterizes acoustic paths crossing the OW. The resulting ray-space image displays the information gathered by the sensors in such a way that the elements of the acoustic scene (sources and reflectors) will be easy to discern, recognize and extract. The key advantage of this method is that ray-space images, irrespective of the application, are generated by a common (and highly parallelizable) processing layer, and can be processed using methods coming from the extensive literature of pattern analysis. After defining the ideal ray-space image in terms of the directional plenacoustic function, we show how to acquire it using a microphone array. We also discuss resolution and aliasing issues and show two simple examples of applications of ray-space imaging.},
author = {Markovi{\'{c}}, Dejan and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
doi = {10.1109/TASL.2013.2274697},
file = {:media/francesco/Data/Mega/Mendeley/Markovi{\'{c}} et al. - 2013 - Soundfield imaging in the ray space.pdf:pdf},
isbn = {1558-7916 VO - 21},
issn = {15587916},
journal = {IEEE Trans. Audio, Speech Lang. Process.},
keywords = {Beam steering,microphone arrays,sound field reconstruction},
number = {12},
pages = {2493--2505},
title = {{Soundfield imaging in the ray space}},
volume = {21},
year = {2013}
}
@inproceedings{Markovic2015a,
abstract = {Soundfield imaging is a novel technique for efficiently encoding, representing and processing the wave field captured by a microphone array. Some of the possible applications include source and reflector localization. In this manuscript we discuss the resolution properties of the soundfield image and the trade-offs that need to be considered while designing the “soundfield camera”. Then we propose a source localization algorithm that exploits multiple soundfield images of the same acoustic scene, acquired with different resolutions, to simultaneously localize acoustic sources with widely different distances from the array.},
address = {New Paltz, NY, USA},
author = {Markovi{\'{c}}, Dejan and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {IEEE Work. Appl. Signal Process. to Audio Acoust.},
doi = {10.1109/WASPAA.2015.7336902},
file = {:media/francesco/Data/Mega/Mendeley/Markovi{\'{c}} et al. - 2015 - Resolution issues in soundfield imaging A multiresolution approach to multiple source localization.pdf:pdf},
isbn = {9781479974504},
keywords = {Acoustic imaging,microphone array,source localization},
pages = {1 -- 5},
publisher = {IEEE},
title = {{Resolution issues in soundfield imaging: A multiresolution approach to multiple source localization}},
year = {2015}
}
@inproceedings{Antonacci2009,
abstract = {This paper proposes a method for the acoustic rendering of a virtual environment based on a geometric decomposition of the wave-field into multiple elementary acoustic beams, all reconstructed with a loudspeaker array. The point of origin, the orientation and the aperture of each beam is computed according to the geometry of the virtual environment that we want to render and to the location of the sources. Space-time filters are computed with a Least Squares approach to render the desired beam. Experimental results show the feasibility as well as the critical issues of the proposed algorithm.},
address = {New Paltz, NY, USA},
author = {Antonacci, Fabio and Calatroni, A. and Canclini, Antonio and Galbiati, A. and Sarti, Augusto and Tubaro, Stefano},
booktitle = {IEEE Work. Appl. Signal Process. to Audio Acoust.},
doi = {10.1109/ASPAA.2009.5346484},
file = {:media/francesco/Data/Mega/Mendeley/Antonacci et al. - 2009 - Soundfield rendering with loudspeaker arrays through multiple beam shaping.pdf:pdf},
isbn = {9781424436798},
issn = {1931-1168},
keywords = {Acoustic beam,Loudspeaker arrays,Wavefield rendering,wavefield rendering},
number = {1},
pages = {313--316},
publisher = {IEEE},
title = {{Soundfield rendering with loudspeaker arrays through multiple beam shaping}},
year = {2009}
}
@article{Markovic2015,
abstract = {A soundfield image is a data structure that efficiently encodes and represents the wave field as captured by a microphone array. Its representation is based on the directional plenacoustic function, which is defined as the radiance of the acoustic paths (rays) that cross the segment that the array lies upon. The sound-field image can be processed " as is " to develop a variety of applications. In its original formulation, the soundfield image is based on a Euclidean parameterization that can accommodate a limited range of rays and is suitable for managing a single array only. In this paper, we generalize this methodology to the case of multiple microphone arrays deployed in space. The use of multiple arrays allows us to capture truly global information on the sound field but requires us to rethink the ray space, and adopt a global repre-sentation of the acoustic rays based on projective geometry. After introducing the new parameterization, we present two examples of applications: the estimation of the mutual poses of two or more arrays (self-calibration); and the localization of multiple acoustic sources. The effectiveness of these applications is proven through simulations as well as real data experiments.},
author = {Markovi{\'{c}}, Dejan and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
doi = {10.1109/TASLP.2015.2419076},
file = {:media/francesco/Data/Mega/Mendeley/Markovi{\'{c}} et al. - 2015 - Multiview Soundfield Imaging in the Projective Ray Space.pdf:pdf},
journal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
keywords = {acoustic measurements,acoustic signal detection,array signal processing},
number = {6},
pages = {1054 -- 1067},
title = {{Multiview Soundfield Imaging in the Projective Ray Space}},
volume = {23},
year = {2015}
}
@article{Markovic2016,
abstract = {Our goal is to develop a model-based approach to acoustic source extraction from microphone array data, which is suitable for both near-field and far-field sources. A signal representation based on plane-wave (PW) decomposition is suitable for acoustic sources in the far field as the resulting spectrum turns out to be impulsive. When the source approaches the array, however, the curvature of the wavefront causes the spectrum of the PW components to depart from impulsive behavior, thus making source extraction harder to attain. In this paper, we adopt a sound field representation based on the local estimation of the plenacoustic function along the array line. This approach consists of dividing the array into subarrays, and applying the PW analysis on individual subarrays. This has the immediate result of extending the range of validity of the far-field hypothesis, as a source that enters the near-field range of the extended array is still in the far-field range of the subarrays. PW analysis on subarrays allows us to construct the so-called sound field map in a domain of acoustic visibility called ray space. The extraction of the desired source is accomplished through spatial filtering of the sound field map. The design of the spatial filter relies on a linear minimum mean square error criterion defined on the sound field map. The effectiveness of the proposed methodology is proven through an extensive simulation campaign as well as real experiments.},
author = {Markovi{\'{c}}, Dejan and Antonacci, Fabio and Bianchi, Lucio and Tubaro, Stefano and Sarti, Augusto},
doi = {10.1109/TASLP.2016.2615242},
file = {:media/francesco/Data/Mega/Mendeley/Markovi{\'{c}} et al. - 2016 - Extraction of Acoustic Sources through the Processing of Sound Field Maps in the Ray Space.pdf:pdf},
issn = {23299290},
journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
number = {12},
pages = {2481--2494},
title = {{Extraction of Acoustic Sources through the Processing of Sound Field Maps in the Ray Space}},
volume = {24},
year = {2016}
}
@inproceedings{Fazi2008,
abstract = {Loudspeakers are widely used in three-dimensional sound field reconstruction systems, but their spatial directivity features are relatively little-known. In this paper, a hemispherical array of 40 microphones was designed and built in order to measure the pressure field radiated by different commercially available loudspeakers. The spatial samples of the acoustic pressure were processed in order to estimate the truncated Fourier-Bessel expansion of the sound field, which allows the reconstruction of the 3D radiation pattern. An analysis of the errors involved in the estimation was also performed with a numerical model of the array.},
address = {Amsterdam, NL},
author = {Fazi, Filippo Maria and Brunel, Vincent and Nelson, Philip A. and H{\"{o}}rchens, Lars and Seo, Jeongil},
booktitle = {AES 124th Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Fazi et al. - 2008 - Measurement and Fourier-Bessel Analysis of Loudspeakers Radiation Patterns Using a Spherical Array of Microphones.pdf:pdf},
publisher = {Audio Engineering Society},
title = {{Measurement and Fourier-Bessel Analysis of Loudspeakers Radiation Patterns Using a Spherical Array of Microphones.}},
year = {2008}
}
@article{Brutti2013,
abstract = {This paper presents a parametric approach to classify the radiation pattern of an acoustic source given the signals captured by multiple microphones. The radiation pattern influences the way the acoustic waves propagate within an enclosure, with direct implications on the behavior of most audio processing algorithms. In particular, the Generalized Cross-Correlation PHAse Transform is affected by the emission pattern as well as by the orientation of the source. A Maximum Likelihood estimator is introduced by using descriptors of the acoustic characteristics of the environment, e.g. wall absorption coefficients and room dimensions, from which models of the observed Generalized Cross-Correlation PHAse Transform are derived for a specific emission pattern. A generic unimodal source directivity is modeled using a parameterized cardioid function. A sub-band implementation is proposed to account for the frequency dependence of the source emission pattern. Experiments on simulated and real data show that the acoustic radiation pattern can be estimated in an effective way under noisy and reverberant conditions. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Brutti, Alessio and Omologo, Maurizio and Svaizer, Piergiorgio},
doi = {10.1016/j.sigpro.2012.09.022},
file = {:media/francesco/Data/Mega/Mendeley/Brutti, Omologo, Svaizer - 2013 - An environment aware ML estimation of acoustic radiation pattern with distributed microphone pairs.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {GCC-PHAT,Microphone arrays,Multichannel audio processing,Radiation pattern estimation},
number = {4},
pages = {784--796},
publisher = {Elsevier},
title = {{An environment aware ML estimation of acoustic radiation pattern with distributed microphone pairs}},
url = {http://dx.doi.org/10.1016/j.sigpro.2012.09.022},
volume = {93},
year = {2013}
}
@article{Ribeiro2011a,
abstract = {The classical approach for acoustic imaging consists of beamforming, and produces the source distribution of interest convolved with the array point spread function. This convolution smears the image of interest, significantly reducing its effective resolution. Deconvolution methods have been proposed to enhance acoustic images and have produced significant improvements. Other proposals involve covariance fitting techniques, which avoid deconvolution altogether. However, in their traditional presentation, these enhanced reconstruction methods have very high computational costs, mostly because they have no means of efficiently transforming back and forth between a hypothetical image and the measured data. In this paper, we propose the Kronecker Array Transform (KAT), a fast separable transform for array imaging applications. Under the assumption of a separable array, it enables the acceleration of imaging techniques by several orders of magnitude with respect to the fastest previously available methods, and enables the use of state-of-the-art regularized least-squares solvers. Using the KAT, one can reconstruct images with higher resolutions than was previously possible and use more accurate reconstruction techniques, opening new and exciting possibilities for acoustic imaging.},
author = {Ribeiro, Fl{\'{a}}vio P. and Nascimento, V{\'{i}}tor H.},
doi = {10.1109/TIP.2011.2118220},
file = {:media/francesco/Data/Mega/Mendeley/Ribeiro, Nascimento - 2011 - Fast Transforms for Acoustic Imaging - Part I Theory.pdf:pdf},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Trans. Image Process.},
keywords = {Acoustic imaging,array imaging,array processing,fast transform,regularized least squares,regularized least-squares,sparse reconstruction},
number = {8},
pages = {2241--2247},
pmid = {21342848},
title = {{Fast Transforms for Acoustic Imaging - Part I: Theory}},
volume = {20},
year = {2011}
}
@phdthesis{Skluzacek2012,
author = {Skluzacek, Simon},
file = {:media/francesco/Data/Mega/Mendeley/Skluzacek - 2012 - Angular Resolution of Human Sound Localization.pdf:pdf},
pages = {1--22},
school = {Carthage College},
title = {{Angular Resolution of Human Sound Localization}},
type = {BSc Thesis},
year = {2012}
}
@phdthesis{Nahas2011,
author = {Nahas, Johnny},
file = {:media/francesco/Data/Mega/Mendeley/Nahas - 2011 - Simulation of array-based sound field synthesis methods.pdf:pdf},
number = {277063},
school = {Aachen University},
title = {{Simulation of array-based sound field synthesis methods}},
type = {MSc Thesis},
year = {2011}
}
@article{Corteel2004,
author = {Corteel, Etienne and Caulkins, Terence},
file = {:media/francesco/Data/Mega/Mendeley/Corteel, Caulkins - 2004 - Sound Scene Creation and Manipulation using Wave Field Synthesis.pdf:pdf},
journal = {Development},
pages = {19},
title = {{Sound Scene Creation and Manipulation using Wave Field Synthesis}},
year = {2004}
}
@inproceedings{Ahrens2007a,
abstract = {Wave field synthesis (WFS) is a spatial audio reproduction technique aiming at physically synthesizing a desired sound field. Typically, virtual sound sources are rendered as emitting spherical or plane waves. In this paper we present an approach to the implementation of sources with arbitrary directivity. The approach is based on the description of the directional properties of a source by a set of circular harmonics. A time domain expression of the loudspeaker driving signals is derived allowing an efficient implementation. Consequences of sampling and truncation of the secondary source distribution as occurring in typical installations of WFS systems are discussed and simulated reproduction results are shown.},
address = {New Paltz, NY, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1704.05420v1},
author = {Ahrens, Jens and Spors, Sascha},
booktitle = {IEEE Work. Appl. Signal Process. to Audio Acoust.},
eprint = {arXiv:1704.05420v1},
file = {:media/francesco/Data/Mega/Mendeley/Ahrens, Spors - 2007 - Implementation of Directional Sources in Wave Field Synthesis.pdf:pdf},
isbn = {9781424416196},
number = {1},
pages = {1--4},
publisher = {IEEE},
title = {{Implementation of Directional Sources in Wave Field Synthesis}},
year = {2007}
}
@book{Zolzer2008,
address = {Chichester, UK},
author = {Z{\"{o}}lzer, Udo},
edition = {2nd},
file = {:media/francesco/Data/Mega/Mendeley/Z{\"{o}}lzer - 2008 - Digital Audio Signal Processing.pdf:pdf},
isbn = {9780470997857},
publisher = {Wiley {\&} Sons, Inc.},
title = {{Digital Audio Signal Processing}},
year = {2008}
}
@article{Olivero2013,
abstract = {We propose here a new approach together with a corresponding class of algorithms for offline estimation of linear operators mapping input to output signals. The operators are modeled as multipliers, i.e., linear and diagonal operator in a frame or Bessel representation of signals (like Gabor, wavelets ldots) and characterized by a transfer function. The estimation problem is formulated as a regularized inverse problem, and solved using iterative algorithms, based on gradient descent schemes. Various estimation problems, which differ by a choice for the regularization function, are studied in the case of Gabor multipliers. The transfer function actually provides a meaningful interpretation of the differences between the two signals or signal classes under consideration, and examples are discussed. Furthermore, examples of signal transformations with such Gabor transfer functions are also given.},
author = {Olivero, Anaik and Torresani, Bruno and Kronland-Martinet, Richard},
doi = {10.1109/TASL.2013.2255274},
file = {:media/francesco/Data/Mega/Mendeley/Olivero, Torresani, Kronland-Martinet - 2013 - A class of algorithms for time-frequency multiplier estimation(2).pdf:pdf},
issn = {15587916},
journal = {IEEE Trans. Audio, Speech Lang. Process.},
keywords = {Analysis/transformation/synthesis,frame multipliers,frame representations},
number = {8},
pages = {1550--1559},
title = {{A class of algorithms for time-frequency multiplier estimation}},
volume = {21},
year = {2013}
}
@book{Olver2010a,
address = {New York, NY, USA},
author = {Olver, Frank W. J. and Lozier, Daniel W. and {Boisvert, Ronald}, F. and Clark, Charles W.},
file = {:media/francesco/Data/Mega/Mendeley/Olver et al. - 2010 - NIST Handbook of Mathematical Functions.pdf:pdf},
isbn = {9780521140638},
publisher = {National Institute of Standards and Technology},
title = {{NIST Handbook of Mathematical Functions}},
year = {2010}
}
@article{Spors2013,
abstract = {This paper reviews the current state of loud- speaker-based spatial sound reproduction methods from technical perspective as well as perceptual perspective. A nomenclature is developed that allows for a strict separation between these two perspectives. The physical fundamentals, practical realization, and results from perceptual studies are discussed for a number of well-established and emerging re- production techniques. Further, the paper outlines novel ap- proaches to spatial sound evaluation in terms of perceived quality and provides a comparison of current approaches.},
author = {Spors, Sascha and Wierstorf, Hagen and Raake, Alexander and Melchior, Frank and Frank, Matthias and Zotter, Franz and Weirstorf, H and Raake, Alexander and Melchior, Frank and Frank, Matthias and Zotter, Franz},
doi = {10.1109/JPROC.2013.2264784},
file = {:media/francesco/Data/Mega/Mendeley/Spors et al. - 2013 - Spatial Sound with Loudspeakers and its Perception A review of the current state.pdf:pdf},
issn = {00189219},
journal = {Proc. IEEE},
keywords = {Evaluation,higher order ambisonics,panning,perception,sound-field synthesis (SFS),spatial sound reproduction,wave field synthesis (WFS)},
number = {9},
pages = {1920--1938},
title = {{Spatial Sound with Loudspeakers and its Perception: A review of the current state}},
volume = {101},
year = {2013}
}
@article{Toole1986a,
abstract = {Precision measurements on loudspeakers have been possible for some time now, and over the years, various views of their importance have developed as aresult of accumulaied experience and scientific investigation. A survey of the literature reveals areas of agreement and disagreement among workers. There is also evidence of geographic concentrations of loudspeaker designers and reviewers who appear to share attitudes toward specific measurements. Part 1 attempts to consolidate published opinion on loudspeaker measurements in preparation for Part 2, which presents the results of some current research on the subject.},
author = {Toole, Floyd E.},
file = {:media/francesco/Data/Mega/Mendeley/Toole - 1986 - Loudspeaker Measurements and Their Relationship to Listener Preferences Part 1.pdf:pdf},
journal = {J. Audio Eng. Soc.},
number = {4},
pages = {227--235},
title = {{Loudspeaker Measurements and Their Relationship to Listener Preferences: Part 1}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=5276},
volume = {34},
year = {1986}
}
@inproceedings{Canclini2015,
abstract = {We propose a method for the estimation of the three-dimensional radiation pattern of violins, during the performance of a musician. A microphone array captures the energy radiated by the violin in different directions using beamforming based on sub-arrays. The 3D radiation pattern is estimated allowing the musician to freely move. In particular, a tracking system estimates the position and orientation of the violin. The adopted system can be also used in a mildly reverberant environment, thus allowing the musician to play in a natural fashion. The experimental results prove the accuracy and the effectiveness of the method.},
address = {Nice, FR},
author = {Canclini, Antonio and Mucci, Luca and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {Eur. Signal Process. Conf.},
doi = {10.1109/EUSIPCO.2015.7362643},
file = {:media/francesco/Data/Mega/Mendeley/Canclini et al. - 2015 - A methodology for estimating the radiation pattern of a violin during the performance.pdf:pdf},
isbn = {9780992862633},
keywords = {Musical acoustics,plenacoustic analysis,radiation pattern},
pages = {1546--1550},
publisher = {IEEE},
title = {{A methodology for estimating the radiation pattern of a violin during the performance}},
year = {2015}
}
@book{Stoica2009,
abstract = {Spectral analysis considers the problem of determining the spectral content (ie, the distribution of power over frequency) of a time series from a finite set of measurements, by means of either nonparametric or parametric techniques. The history of spectral analysis ...},
address = {Upper Saddle River, NJ, USA},
author = {Stoica, Petre and Moses, Randolph},
doi = {10.1002/9780470823767.ch2},
edition = {1st},
editor = {Robbins, Tom},
file = {:media/francesco/Data/Mega/Mendeley/Stoica, Moses - 2009 - Spectral Analysis of Signals.pdf:pdf},
isbn = {9780470823743},
issn = {1678-4375},
pmid = {21085779},
publisher = {Prentice Hall},
title = {{Spectral Analysis of Signals}},
url = {http://doi.wiley.com/10.1002/9780470823767.ch2},
year = {2009}
}
@article{Berkhout1993,
abstract = {The acoustics in auditoria are determined by the properties of both the direct sound and the later arriving reflections. If electroacoustic means are used to repair disturbing deficiencies in the acoustics, one has to cope with unfavorable side effects such as localization problems and artificial impressions of the reverberant field (electronic flavor). To avoid those side effects, the concept of electroacoustic wave front synthesis is introduced. The underlying theory is based on the Kirchhoff–Helmholtz integral. In this new concept the wave fields of the sound sources on stage are measured by directive microphones; next they are electronically extrapolated away from the stage, and finally they are re‐emitted in the hall by one or more loudspeaker arrays. The proposed system aims at emitting wave fronts that are as close as possible to the real wave fields. Theoretically, there need not be any differences between the electronically generated wave fields and the real wave fields. By using the image source concept, reflections can be generated in the same way as direct sound.},
archivePrefix = {arXiv},
arxivId = {10.1121/1.405852},
author = {Berkhout, A. J. and {De Vries}, D. and Vogel, P.},
eprint = {1.405852},
file = {:media/francesco/Data/Mega/Mendeley/Berkhout, De Vries, Vogel - 1993 - Acoustic Control by Wave Field Synthesis.pdf:pdf},
journal = {J. Acoust. Soc. Am.},
number = {5},
pages = {2764 -- 2778},
primaryClass = {10.1121},
title = {{Acoustic Control by Wave Field Synthesis}},
volume = {93},
year = {1993}
}
@phdthesis{Daniel2001,
abstract = {This thesis deals with acoustic field representation for spatial reproduction over loudspeakers or headphones, as ap- plied to the large multimedia domain, including newapplications for browsing in virtual composite 3D-scenes on the In- ternet. This domain combines spatial reproduction of pre-existent complex sound fields (e.g. in the "5.1" multi-channel format) and constructive spatialisation tasks (3D pan-pot and room effects). This kind of application is increasingly characterised by the variability of a number of parameters: transmission bit-rate, user resources (CPU, reproduction layout), listening conditions (individual or collective), diversity of sound or audio-visual material handled, view-point and object positions in the virtual environment (interactivity). The problem of the representation seen as a set of signals to be directly diffused or to be decoded before concerns the transmission (purpose of conciseness) as well as the intermediary spatialisation step (global encoding to factorise the next process). We have chosen to study thoroughly the ambisonic approach, which is based on spherical harmonic decomposition of the acoustic field, centred on the listener view-point. It has been known for a long time as a first order restricted form, which processes a minimal, directional sound field encoding through four components (B-format):W(pressure) and X, Y, Z (pressure gradient), offering easy sound field manipulations, such as rotations.With a decoder optimised in terms of the listening conditions (ideal/centred or collective/off-centred), a coherent and homogeneous sound space rendering can be obtained for various panoramic (2D) or periphonic (3D) loudspeaker rigs. This "variable geometry" rendering extends to headphones or a pair of loudspeakers via binaural techniques (virtual loudspeakers). The consideration of higher order components, which have just begun to be studied, introduces the concept of "variable resolution" representation (scalability), used as a function of the number of loudspeakers and/or the transmission capability. We present acoustic and psychoacoustic foundations and a critical review of spatialisation strategies (stereo, sur- round, binaural, transaural and new derived forms).We explain the intrinsic link between ambisonic representation and local (velocity vector V) and global (energy vector E) propagation characteristics of the reproduced sound field (consi- dering also the loudspeaker geometry), and the prediction laws between the latter and the localisation effect according to the head moving. Thus, the localisation theories implied in ambisonic decoding (Gerzon) are thoroughly justified. While being extended to other reviewed approaches, this kind of analysis highlights Ambisonic. The generalisation of Ambisonic to all higher orders involves all the aspects presented for the first order systems, especially the encoding formalism and the decoding principles (2D and 3D).We develop the notion of directional sam- pling of the spherical harmonic base (also usable for the sound field pick-up problem), then the three original decoding forms (Gerzon, Malham) are generalised into three solution families, to be applied according to the listening conditions. Objective evaluations supported by informal listening experiments confirm the contribution of the higher orders and the optimised solutions. The improvement appears through the radial expansion of the acoustic field reconstruction and the global propagation E), or with regard to the perceptive aspects, through the sound image precision and robustness even in non-ideal conditions and the preservation of spatial impressions (lateral separation, a bit weak with the first order). In addition to Ambisonic (tested up to the second order), other spatialisation techniques (pan-pot, binaural, trans- aural, plus artificial reverberation) are implemented, incorporated in an interface on a PC, and then experimented. This way, Ambisonic has been successfully applied to real-time source manipulation and mixing (with mono, multi-channel and B-format as input sources), and also compared or combined with other techniques, over headphones (binaural mode) as well as over loudspeakers. This tool could be used for a complete subjective validation of the ambisonic approach and the underlying strategies. The ambisonic approach gives a very satisfying, global solution to the initial issues, although other strategies are better suited for specific problems surround matrix systems, efficient binaural synthesis of complex scenes. Its extension to higher orders concerns many application fields and should develop in the near future thanks to the current studies and projects.},
author = {Daniel, J{\'{e}}r{\^{o}}me},
file = {:media/francesco/Data/Mega/Mendeley/Daniel - 2001 - Repr{\'{e}}sentation de champs acoustiques, application {\`{a}} la transmission et {\`{a}} la reproduction de sc{\`{e}}nes sonores complexe.pdf:pdf},
keywords = {3D Sound,3D browsing,Ambisonics,B-format,Directional sampling,Energy Vector,Localization Theory,Multimedia,Psychoacoustic decoding,Scalability,Sound field representation,Spatialization,Spherical harmonic decomposition,Surround,Velocity Vector},
pages = {319},
school = {Universit{\'{e}} Paris 6},
title = {{Repr{\'{e}}sentation de champs acoustiques, application {\`{a}} la transmission et {\`{a}} la reproduction de sc{\`{e}}nes sonores complexes dans un contexte multim{\'{e}}dia}},
type = {PhD Dissertation},
url = {http://pcfarina.eng.unipr.it/Public/phd-thesis/jd-these-original-version.pdf},
year = {2001}
}
@book{Benesty2008,
abstract = {From common consumer products such as cell phones and MP3 players to more sophisticated projects such as human-machine interfaces and responsive robots, speech technologies are now everywhere. Many think that it is just a matter of time before more applications of the science of speech become inescapable in our daily life. This handbook is meant to play a fundamental role for sustainable progress in speech research and development. Springer Handbook of Speech Processing targets three categories of readers: graduate students, professors and active researchers in academia and research labs, and engineers in industry who need to understand or implement some specific algorithms for their speech-related products. The handbook could also be used as a sourcebook for one or more graduate courses on signal processing for speech and different aspects of speech processing and applications. A quickly accessible source of application-oriented, authoritative and comprehensive information about these technologies, it combines the established knowledge derived from research in such fast evolving disciplines as Signal Processing and Communications, Acoustics, Computer Science and Linguistics.},
address = {Berlin, Germany},
author = {Benesty, Jacob and Sondhi, Mohan M. and Huang, Yiteng and Greenberg, Steven},
doi = {10.1007/978-3-540-49127-9},
edition = {1st},
editor = {Benesty, Jacob and Sondhi, Mohan M. and Huang, Yiteng},
file = {:media/francesco/Data/Mega/Mendeley/Benesty et al. - 2008 - Springer Handbook of Speech Processing.pdf:pdf},
isbn = {978-3-540-49125-5},
issn = {00014966},
pages = {1176},
publisher = {Springer},
title = {{Springer Handbook of Speech Processing}},
url = {http://link.springer.com/10.1007/978-3-540-49127-9},
year = {2008}
}
@inproceedings{Neukom2007,
abstract = {Ambisonics is a surround-system for encoding and rendering a 3D sound field. Sound is encoded and stored in multi-channel sound files and is decoded for playback. In this paper a panning function equivalent to the result of ambisonic encoding and so-called in-phase decoding is presented. In this function the order of ambisonic resolution is just a variable that can be an arbitrary positive number not restricted to integers and that can be changed during playback. The equivalence is shown, limitations and advantages of the technique are mentioned and real time applications are described.},
address = {New York, NY, USA},
author = {Neukom, Martin},
booktitle = {AES 123rd Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Neukom - 2007 - Ambisonic Panning.pdf:pdf},
isbn = {9781604239027 (ISBN)},
keywords = {7297},
pages = {1--7},
publisher = {Audio Engineering Society},
title = {{Ambisonic Panning}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=14354},
year = {2007}
}
@inproceedings{Teutsch2013,
abstract = {In this paper a real-time system for immersive audio applications is presented. Sound sources are recorded using a microphone array whose beam is steered according to the output of an acoustic source localization and tracking system. The output of the beamformer (BF) along with the source position updates are continuously transmitted to a wave field synthesis (WFS) system. By using WFS the sound sources in the recording room are rendered in the reproduction room with the correct spatial cues.},
address = {New Paltz, NY, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1704.05420v1},
author = {Teutsch, H. and Spors, Sascha and Herbordt, W. and Kellermann, Walter and Rabenstein, Rudolf},
booktitle = {IEEE Work. Appl. Signal Process. to Audio Acoust.},
eprint = {arXiv:1704.05420v1},
file = {:media/francesco/Data/Mega/Mendeley/Teutsch et al. - 2003 - An Integrated Real-time System for Immersive Audio Applications.pdf:pdf},
isbn = {9781424416196},
number = {1},
pages = {1--4},
publisher = {IEEE},
title = {{An Integrated Real-time System for Immersive Audio Applications}},
year = {2003}
}
@inproceedings{Ahrens2008,
abstract = {In this paper, we present the derivation and investigation of analytical expressions for the loudspeaker driving signals for higher order Ambisonics. The approach relies on the assumption of a continuous distribution of secondary sources on which sampling is performed to yield the actual loudspeaker signals for real-world implementations. For source-free volumes enclosed by the secondary source distribution, this formulation of Ambisonics leads to what is known as simple source approach. Since the simple source approach is theoretically well documented, we will depart from it and concentrate on the special case of a circular distribution of secondary point sources and derive analytical expressions for the driving signals. We furthermore derive a closed-form expression for the actual reproduced wave field for the circular secondary source distribution.},
author = {Ahrens, Jens and Spors, Sascha},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
doi = {10.1109/ICASSP.2008.4517624},
file = {:media/francesco/Data/Mega/Mendeley/Ahrens, Spors - 2008 - Analytical driving functions for higher order ambisonics.pdf:pdf},
isbn = {1424414849},
issn = {15206149},
keywords = {Ambisonics,Audio reproduction in a plane,Spatial audio,Spherical harmonics,simple source approach},
pages = {373--376},
pmid = {4517624},
title = {{Analytical driving functions for higher order ambisonics}},
year = {2008}
}
@inproceedings{Ahrens2010,
abstract = {Near-field compensated higher order Ambisonics (HOA) is an approach to the physical synthesis of sound fields. The typical interpretation of the modern HOA approach is that the sound field to be synthesized and the spatio-temporal transfer function of the employed loudspeakers are expanded into series of spherical harmonics in order to determine the loudspeaker driving signals for spherical arrays. Going one level higher in abstraction, HOA can be interpreted as the single-layer potential solution to the problem which is solved via a formulation of the reproduction equation in a spatial frequency domain which is selected according to the geometry of the loudspeaker array. For spherical arrays, this spatial frequency domain is the spherical harmonics domain. The presented paper provides an overview over a recent extension of this approach to the employment of planar and linear loudspeaker arrays. In this latter situation, the solution is obtain via a formulation of the reproduction equation in wavenumber domain.},
address = {Paris, FR},
author = {Ahrens, Jens and Spors, Sascha},
booktitle = {Int. Symp. Ambisonics Spherical Acoust.},
editor = {Noisternig, Markus and Misdariis, Nicolas},
file = {:media/francesco/Data/Mega/Mendeley/Ahrens, Spors - 2010 - Applying the Ambisonics Approach on Planar and Linear Arrays of Loudspeakers.pdf:pdf},
number = {3},
publisher = {IRCAM},
title = {{Applying the Ambisonics Approach on Planar and Linear Arrays of Loudspeakers}},
url = {http://ambisonics10.ircam.fr/drupal/indexbb54.html?q=proceedings/o3},
year = {2010}
}
@inproceedings{Ahrens2007,
abstract = {Higher order Ambisonics (HOA) is a spatial audio reproduction technique aiming at physically synthesizing a desired sound field. It is based on the expansion of sound fields into orthogonal basis functions (spatial harmonics). In this paper we present an approach to the two-dimensional reproduction of virtual sound sources at arbitrary positions having arbitrary radiation directivities. The approach is based on the description of the directional properties of a source by a set of circular harmonics. Consequences of truncation of the circular harmonics expansion and spatial sampling as occurring in typical installations of HOA systems due to the employment of a finite number of loudspeakers are discussed. We illustrate our findings with simulated reproduction results.},
address = {New York, NY, USA},
author = {Ahrens, Jens and Spors, Sascha},
booktitle = {AES 123rd Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Ahrens, Spors - 2007 - Rendering of virtual sound sources with arbitrary directivity in higher order Ambisonics.pdf:pdf},
isbn = {9781604239027},
keywords = {Acoustic field measurement,Acoustic fields,Harmonic analysis,Societies and institutions,Sound reproduction},
pages = {65--73},
publisher = {Audio Engineering Society},
title = {{Rendering of virtual sound sources with arbitrary directivity in higher order Ambisonics}},
volume = {1},
year = {2007}
}
@phdthesis{Verheijen1997,
abstract = {Sound reproduction comprises the recording, storage and playback of sound (esp. music). Since the 1950s, sound reproduction is mainly based on stereophonic techniques. In two-channel stereophony, the sound is recorded with a pair of main microphones placed in front of the source area (e.g. a symphony orchestra). Separate sound sources or groups of sound sources are often recorded by spot microphones as well. These signals are mixed with those of the main pair, and are reproduced by two loudspeakers. A listener seated midway in front of these loudspeakers, perceives a sound image similar to that of the original sources concerning color, depth and balance. A listener seated off-center experiences a spatially distorted sound image, that inclines to the nearest loudspeaker. Thus, the listening area for stereophonic reproduction is restricted to a few seats midway between both loudspeakers. In this thesis a new method of sound reproduction is described, based on the theory of wave field synthesis. Through the use of arrays of loudspeakers, driven by processed copies of the source signals, it is possible to synthesize wave fronts that are almost identical to those of the original sound sources. Hence, this method of reproduction offers a volume-solution, instead of the point-solution of conventional reproduction methods. The processing of the original source signals is done by the synthesis operator, which is derived from the Kirchhoff-Helmholtz wave field representation. This theory describes the distribution of the pressure and particle velocity on a closed surface as a consequence of (primary) sources outside the enclosed volume. If this surface (of arbitrary shape) is filled with secondary dipole and monopole sources, theoretically a perfect copy of the primary wave field can be obtained inside the enclosure. For the special geometry of a planar distribution of secondary sources, Rayleigh's integrals apply. Then, with the primary sources behind that plane, either monopoles or dipoles suffice to generate a copy of the primary wave field in front of that plane. In practice, planar arrays of loudspeakers (secondary sources) can be used to synthesize virtual sources (primary sources). Another geometrical simplification is allowed if the virtual sources as well as the listeners are present in a horizontal plane. In that case, a horizontal line array of loudspeakers suffices. By means of focusing techniques it is also possible to create sound sources in front of the loudspeakers: the listeners will then perceive a source at the acoustic focus. Because of the finite distance between adjacent loudspeakers of the array, there will be spectral deviations above a certain frequency in the reproduced wave field: effects of spatial aliasing. From theory it arises that the synthesized sound field approaches the original field more closely, if the loudspeakers radiate the sound in a more directional way. The directional behavior of the loudspeakers can be controlled by modeling the diaphragm that radiates the sound. For that reason, best results are to be expected for electrostatic loudspeakers. A prototype array, built according to these discernments, confirms that is possible to synthesize a wave field that is also correct for higher frequencies. However, the efficiency of this prototype array is too low for practical applications in wave field synthesis, for which reason an electrodynamic array has been developed as well. A 128-channel reproduction system has been built, which includes these electrodynamic arrays surrounding a 24 m² listening area. This system composes the wave field per source as follows: its direct sound (recorded with a spot microphone) is reproduced by a virtual source, its early reflections (computed by a mirror source program) are also synthesized by virtual sources, and its reverberant field (picked up by ambient microphones, or generated by artificial reverberation units) is composed by means of plane waves entering from different directions. Also, fast moving sources (recorded by close-miking) can be synthesized, which is considered to be an important requirement for application in cinemas, simulators and virtual reality theaters. This reproduction system is evaluated in two ways: by measurements (objectively) and by listening tests (subjectively). In a comparative investigation between wave field synthesis, stereophony and 3/2 surround sound, it is shown that the wave field synthesis system offers the largest listening area with spatially correct reproduction of sound. Its sound image is more robust than that of the other systems. Also, this system is able to evoke a very spatial impression, in which the loudspeakers cannot be distinguished any more. Furthermore, the flexibility of the system regarding the manipulation of source positions and ambience is an important innovation.},
author = {Verheijen, Edwin},
file = {:media/francesco/Data/Mega/Mendeley/Verheijen - 1997 - Sound Reproduction by Wave Field Synthesis.pdf:pdf},
school = {TU Delft},
title = {{Sound Reproduction by Wave Field Synthesis}},
type = {PhD},
url = {http://www.dbvision.nl/bestanden/overons/publicaties/ouder/Thesis{\_}Edwin{\_}Verheijen.pdf},
year = {1997}
}
@book{Ahrens2012,
abstract = {The present book summarizes the work that I have performed in the context of my doctoral dissertation and my subsequent activities at the Quality and Usability Lab, which is jointly run by the University of Technology Berlin and Deutsche Telekom Laboratories. The initial motivation for this work has been the question of how the two best-known methods of sound field synthesis, namely Wave Field Synthesis and Near-field Compensated Higher Order Ambisonics, relate. The answer to this question had been discussed in the research communities for years but a convincing conclusion had not been found. I present in this book a general formulation for the problem of sound field synthesis that allows for identifying above methods as particular solutions so that a juxtaposition is straightforward. Practical applications and synthesis of sound fields with diverse properties are then treated based on the general framework, which further facilitates the interpretation. The website http://www.soundfieldsynthesis.org accompanying this book makes available for download MATLAB/Octave scripts for all included simulations so that the reader can perform further investigations without having to start from scratch. As with any book, the people who deserve acknowledgements are too numerous to list. I therefore mention only those who receive my very special acknowledgements. All others who have contributed to my research work and who are not mentioned here shall be aware of my appreciation. Special thanks go to Sebastian M{\"{o}}ller for putting immeasurable efforts in providing perfect working conditions and for giving me the freedom to work on the topic of sound field synthesis. And, of course, I thank him for reviewing my doctoral dissertation. Irene Hube-Achter's efforts have also contributed to a considerable extent to the pleasantness of my working conditions which I am also very thankful for. Jens Blauert deserves general acknowledgements for exciting and inspiring discussions over the years; and he deserves special acknowledgements for reviewing my dissertation and for giving valuable comments and suggestions. Frank Schultz has also given valuable comments on my dissertation. I wish to thank all of my colleagues at Quality and Usability Lab, most notably Matthias Geier, Karim Helwani and Hagen Wierstorf of the audio technology group, Warcel W{\"{a}}ltermann and Alexander Raake, and I wish to thank the management of Deutsche Telekom Laboratories for their support and enthusiasm for spatial audio. The last and thus most important paragraph is dedicated to Sascha Spors who deserves most pronounced acknowledgments for various efforts including introducing me to the topic of sound field synthesis, guiding me through all these years that I have spent at Quality and Usability Lab and Deutsche Telekom Laboratories, and also for organizing my employment after a single phone call. And finally, I am especially thankful for the fact that we have shared and do still share so many of our interests and for the coincidence that brought us together.},
address = {Berlin, Germany},
author = {Ahrens, Jens},
doi = {10.1007/978-3-642-25743-8},
edition = {1st},
editor = {M{\"{o}}ller, Sebastian and K{\"{u}}pper, Axel and Raake, Alexander},
file = {:media/francesco/Data/Mega/Mendeley/Ahrens - 2012 - Analytical Methods of Sound Field Synthesis.pdf:pdf},
isbn = {9783642184628},
publisher = {Springer},
title = {{Analytical Methods of Sound Field Synthesis}},
year = {2012}
}
@article{Pinto2010,
abstract = {Consider a nonparametric representation of acoustic wave fields that consists of observing the sound pressure along a straight line or a smooth contour L defined in space. The observed data contains implicit information of the surrounding acoustic scene, both in terms of spatial arrangement of the sources and their respective temporal evolution. We show that such data can be effectively analyzed and processed in what we call the space-time-frequency representation space, consisting of a Gabor representation across the spatio-temporal manifold defined by the spatial axis L and the temporal axis t. In the presence of a source, the spectral patterns generated at L have a characteristic triangular shape that changes according to certain parameters, such as the source distance and direction, the number of sources, the concavity of L, and the analysis window size. Yet, in general, the wave fronts can be expressed as a function of elementary directional components-most notably, plane waves and far-field components. Furthermore, we address the problem of processing the wave field in discrete space and time, i.e., sampled along L and t, where a Gabor representation implies that the wave fronts are processed in a block-wise fashion. The key challenge is how to chose and customize a spatio-temporal filter bank such that it exploits the physical properties of the wave field while satisfying strict requirements such as perfect reconstruction, critical sampling, and computational efficiency. We discuss the architecture of such filter banks, and demonstrate their applicability in the context of real applications, such as spatial filtering, deconvolution, and wave field coding.},
author = {Pinto, Francisco and Vetterli, Martin},
doi = {10.1109/TSP.2010.2052045},
file = {:media/francesco/Data/Mega/Mendeley/Pinto, Vetterli - 2010 - Space-Time-Frequency Processing of Acoustic Wave Fields Theory, Algorithms, and Applications.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Trans. Signal Process.},
keywords = {Array signal processing,beamforming,directional filter banks,source localization,space-time-frequency analysis,spatial filtering,wave field coding},
number = {9},
pages = {4608--4620},
title = {{Space-Time-Frequency Processing of Acoustic Wave Fields: Theory, Algorithms, and Applications}},
url = {10.1109/TSP.2010.2052045{\%}5Cnhttp://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp={\&}arnumber=5482103},
volume = {58},
year = {2010}
}
@book{Williams1999,
abstract = {Relying little on material outside the book, Fourier Acoustics will be invaluable as a graduate level text as well as a reference for researchers in academia ...},
address = {London, UK},
annote = {Rayleigh's first integrals -{\textgreater} radiation pattern},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Williams, Earl G.},
booktitle = {Book},
doi = {10.1016/B978-012753960-7/50004-8},
eprint = {9809069v1},
file = {:media/francesco/Data/Mega/Mendeley/Williams - 1999 - Fourier Acoustics Sound Radiation and Nearfield Acoustic Holography.pdf:pdf},
isbn = {0127539603},
issn = {0717-6163},
keywords = {Science},
pages = {306},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
publisher = {Academic Press},
title = {{Fourier Acoustics: Sound Radiation and Nearfield Acoustic Holography}},
year = {1999}
}
@inproceedings{Mabande2007,
abstract = {In this paper, the superdirective beamforming principle as applied to loudspeaker arrays is investigated. Novel superdirectional beamformer designs (e.g. by Parra, [1]) offer significant spatial selectivity at low frequencies and allow for a small array aperture and some variability in loudspeaker positioning. The theoretical gains of superdirectional beamforming are generally difficult to obtain in practice due to the extreme sensitivity of these beamformers to small random errors and the amplification of spatially white noise, such as transducer self-noise. Passive loudspeakers, unlike microphones, do not suffer from self-noise, but their directivity patterns are usually not well defined, so that deviations between different speakers are common, which act similar to random errors. The results of a succinct sensitivity analysis of an exemplary design [1] are shown in this paper. The use of matched loudspeaker arrays promises an improvement in the performance of superdirectional loudspeaker arrays.},
address = {Madrid, ES},
author = {Mabande, Edwin and Kellermann, Walter},
booktitle = {Int. Congr. Acoust.},
doi = {10.1.1.144.1653},
file = {:media/francesco/Data/Mega/Mendeley/Mabande, Kellermann - 2007 - Towards superdirective beamforming with loudspeaker arrays.pdf:pdf},
pages = {1--6},
title = {{Towards superdirective beamforming with loudspeaker arrays}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.1653{\&}rep=rep1{\&}type=pdf},
year = {2007}
}
@article{Kowalczyk2015,
abstract = {Flexible and efficient spatial sound acquisition and subsequent processing are of paramount importance in communication and assisted listening devices such as mobile phones, hearing aids, smart TVs, and emerging wearable devices (e.g., smart watches and glasses). In application scenarios where the number of sound sources quickly varies, sources move, and nonstationary noise and reverberation are commonly encountered, it remains a challenge to capture sounds in such a way that they can be reproduced with a high and invariable sound quality. In addition, the objective in terms of what needs to be captured, and how it should be reproduced, depends on the application and on the user's preferences. Parametric spatial sound processing has been around for two decades and provides a flexible and efficient solution to capture, code, and transmit, as well as manipulate and reproduce spatial sounds. Instrumental to this type of processing is a parametric model that can describe a sound field in a compact and general way. In most cases, the sound field can be decomposed into a direct sound component and a diffuse sound component. These two components together with parametric side information such as the direction-of-arrival (DOA) of the direct sound component or the position of the sound source, provide a perceptually motivated description of the acoustic scene [1]–[3]. In this article, we provide an overview of recent advances in spatial sound capturing, manipulation, and reproduction based on such parametric descriptions of the sound field. In particular, we focus on two established parametric descriptions presented in a unified way and show how the signals and parameters can be obtained using multiple microphones. Once the sound field is analyzed, the sound scene can be transmitted, manipulated, and synthesized depending on the application. For example, sounds can be extracted from a specific direction or from a specific arbitrary two-dimensional or even three-dimensional region of interest. Furthermore, the sound scene can be manipulated to create an acoustic zoom effect in which direct sounds within the listening angular range are amplified depending on the zoom factor, while other sounds are suppressed. In addition, the signals and parameters can be used to create surround sound signals. As the manipulation and synthesis are highly application dependent, we focus in this article on three illustrative assisted listening applications: spatial audio communication, virtual classroom, and binaural hearing aids.},
author = {Kowalczyk, Konrad and Thiergart, Oliver and Taseska, M and Galdo, G Del and Pulkki, Ville and Cristoferetti, L. and Habets, Emanu{\"{e}}l A. P.},
file = {:media/francesco/Data/Mega/Mendeley/Kowalczyk et al. - 2015 - Parametric Spatial Sound Processing.pdf:pdf},
journal = {IEEE Signal Process. Mag.},
number = {2},
pages = {31--42},
title = {{Parametric Spatial Sound Processing}},
volume = {32},
year = {2015}
}
@article{Corteel2007,
abstract = {The synthesis of directional sources using wave field synthesis is described. The proposed formulation relies on an ensemble of elementary directivity functions based on a subset of spherical harmonics. These can be combined to create and manipulate directivity characteristics of the synthesized virtual sources. The WFS formulation introduces artifacts in the synthesized sound field for both ideal and real loudspeakers. These artifacts can be partly compensated for using dedicated equalization techniques. A multichannel equalization technique is shown to provide accurate results thus enabling for the manipulation of directional sources with limited reconstruction artifacts. Applications of directional sources to the control of the direct sound field and the interaction with the listening room are discussed.},
author = {Corteel, Etienne},
doi = {10.1155/2007/90509},
file = {:media/francesco/Data/Mega/Mendeley/Corteel - 2007 - Synthesis of directional sources using wave field synthesis, possibilities, and limitations.pdf:pdf},
issn = {11108657},
journal = {EURASIP J. Adv. Signal Process.},
number = {1},
title = {{Synthesis of directional sources using wave field synthesis, possibilities, and limitations}},
volume = {2007},
year = {2007}
}
@incollection{Gill1981,
author = {Gill, P. E. and Murray, W. and Wright, M. H.},
booktitle = {Pract. Optim.},
file = {:media/francesco/Data/Mega/Mendeley/Gill, Murray, Wright - 1981 - Nonlinear Constraints.pdf:pdf},
pages = {205--260},
title = {{Nonlinear Constraints}},
volume = {0},
year = {1981}
}
@inproceedings{Lardies2012,
abstract = {The problem of estimating the power of signals impinging an array of sensors when the arrival directions are known is presented. It is assumed that the signal field at the array is comprised of P independent plane-wave arrivals from known directions. In practice the directions of arrival are rarely known exactly, however this difficulty can be overcome by using the standard MUSIC (Multiple Signal Classification) algorithm, which constitutes an angular pseudo-spectrum and an indicator of directions of arrival of different signals. The problem then reduces to the estimation of the signal powers from each of the P directions. Five estimators are presented in this communication. The conventional beamformer, the Capon estimator, the robust Capon estimator, the covariance vector estimator and the least squares fit estimator of the observed cross-spectral matrix of the array. Numerical and experimental results are presented showing that the performances of the covariance vector estimators are better than other estimators.},
address = {Nantes, FR},
author = {Lardies, Joseph and Ma, Hua and Berthillier, Marc},
booktitle = {Acoust. 2012 Nantes},
file = {:media/francesco/Data/Mega/Mendeley/Lardies, Ma, Berthillier - 2012 - Power estimation of acoustical sources by an array of microphones.pdf:pdf},
pages = {2919--2924},
publisher = {HAL},
title = {{Power estimation of acoustical sources by an array of microphones}},
year = {2012}
}
@phdthesis{Borra2016,
abstract = {In the past few years, the problem of acoustic source separation using microphone arrays has gained interest in research and industry communities. The goal of this thesis is to develop a flexible methodology to address the problem, which is also able to manage multiple arrays distributed in the space. The use of multiple arrays allows us to capture truly global information about the sound field, but it is necessary to adopt a suitable representation for the signals. Among the different representation paradigms of the sound field present in the literature, we adopted a particular one inspired by geometrical acoustics, which is based on a description of the sound field in terms of acoustic rays. In particular, we have taken advantage of a powerful tool, known as ray space transform, in order to efficiently map the sound field information acquired by a microphone array onto a domain known as ray space. Points in this domain represent rays in the geometric space. Since we wanted to design a source separation approach able to manage multiple arrays, we could not directly use this tool, but a re-parametrization was necessary. The great advantage of this representation is that it gives a great insight on the acoustic scene under analysis and allows for a detailed design of the filtering process. The computation of the ray space representation trough this tool represents the step preceding that of the filter design and the actual filtering process, which are at the core of our system. The filter design is here approached as a two step procedure, which aims at minimising the interferences, while leaving undistorted the desired sound. The first step fully exploits the geometric intuition behind the ray space representation by selecting which elements in this domain should be kept and which discarded, while the second step is based on an optimization procedure. Another important advantage of the approach presented is that the overall filter design process needs only the position of the sources in the acoustic scene while no a-priori knowledge on the emitted signals is necessary. As a consequence, the filter coefficients can be easily precomputed and stored for a given set of positions. Through simulations and experiments we have proven that this approach is effective also in challenging acoustic scenes and that the use of multiple arrays brings great improvements concerning both the accuracy of the separation and the quality of the extracted signal.},
author = {Borra, Federico},
file = {:media/francesco/Data/Mega/Mendeley/Borra - 2016 - A flexible methodology for acoustic source extraction based on the Ray Space Transform.pdf:pdf},
school = {Politecnico di Milano},
title = {{A flexible methodology for acoustic source extraction based on the Ray Space Transform}},
type = {MSc},
year = {2016}
}
@phdthesis{Ajdler2006,
abstract = {The spatialization of the sound field in a room is studied, in particular the evolution of room impulse responses as a function of their spatial positions. It was observed that the multidimensional spectrum of the solution of the wave equation has an almost bandlimited character. Therefore, sampling and interpolation can easily be applied using signals on an array. The decay of the spectrum is studied on both temporal and spatial frequency axes. The influence of the decay on the performance of the interpolation is analyzed. Based on the support of the spectrum, the number and the spacing between the microphones is determined for the reconstruction of the sound pressure field up to a certain temporal frequency and with a certain reconstruction quality. The optimal sampling pattern for the microphone positions is given for the linear, planar and three-dimensional case. Existing techniques usually make use of room models to recreate the sound field present at some point in the space. The presented technique simply starts from the measurements of the sound pressure field in a finite number of positions and with this information the sound pressure field can be recreated at any spatial position. Finally, simulations and experimental results are presented and compared with the theory},
author = {Ajdler, Thibaut},
doi = {10.1109/TSP.2006.879280},
file = {:media/francesco/Data/Mega/Mendeley/Ajdler - 2006 - The plenacoustic function and its applications.pdf:pdf},
isbn = {0-7803-7850-4},
issn = {1053587X},
keywords = {Interpolation,Plenoptic function,Room impulse response,Sampling,Sound pressure field sampling},
number = {10},
pages = {3790--3804},
pmid = {1703848},
school = {{\'{E}}cole Polytechnique F{\'{e}}d{\'{e}}rale de Lausanne},
title = {{The plenacoustic function and its applications}},
type = {PhD},
volume = {54},
year = {2006}
}
@article{Wu2009,
abstract = {Reproduction of a soundfield is a fundamental problem in acoustic signal processing. A common approach is to use an array of loudspeakers to reproduce the desired field where the least-squares method is used to calculate the loudspeaker weights. However, the least-squares method involves matrix inversion which may lead to errors if the matrix is poorly conditioned. In this paper, we use the concept of theoretical continuous loudspeaker on a circle to derive the discrete loudspeaker aperture functions by avoiding matrix inversion. In addition, the aperture function obtained through continuous loudspeaker method reveals the underlying structure of the solution as a function of the desired soundfield, the loudspeaker positions, and the frequency. This concept can also be applied for the 3-D soundfield reproduction using spherical harmonics analysis with a spherical array. Results are verified through computer simulations.},
author = {Wu, Yan Jennifer and Abhayapala, Thushara D.},
doi = {10.1109/TASL.2008.2005340},
file = {:media/francesco/Data/Mega/Mendeley/Wu, Abhayapala - 2009 - Theory and design of soundfield reproduction using continuous loudspeaker concept.pdf:pdf},
isbn = {1424414849},
issn = {15587916},
journal = {IEEE Trans. Audio, Speech Lang. Process.},
keywords = {Array of loudspeakers,Continuous loudspeaker multichannel audio,Soundfield reproduction},
number = {1},
pages = {107--116},
pmid = {4723693},
title = {{Theory and design of soundfield reproduction using continuous loudspeaker concept}},
volume = {17},
year = {2009}
}
@article{Qian1993,
abstract = {A feasible algorithm for implementing the Gabor expansion, the$\backslash$ncoefficients of which are computed by the discrete Gabor transform$\backslash$n(DGT), is presented. For a given synthesis window and sampling pattern,$\backslash$ncomputing the auxiliary biorthogonal function of the DGT is nothing more$\backslash$nthan solving a linear system. The DGT presented applies for both finite$\backslash$nas well as infinite sequences. By exploiting the nonuniqueness of the$\backslash$nauxiliary biorthogonal function at oversampling an orthogonal like DGT$\backslash$nis obtained. As the discrete Fourier transform (DFT) is a discrete$\backslash$nrealization of the continuous-time Fourier transform, similarly, the DGT$\backslash$nintroduced provides a feasible vehicle to implement the useful Gabor$\backslash$nexpansion},
author = {Qian, Shie and Chen, Dapang},
doi = {10.1109/78.224251},
file = {:media/francesco/Data/Mega/Mendeley/Qian, Chen - 1993 - Discrete Gabor Transform.pdf:pdf},
isbn = {0780350731},
issn = {19410476},
journal = {IEEE Trans. Signal Process.},
number = {7},
pages = {2429--2438},
title = {{Discrete Gabor Transform}},
volume = {41},
year = {1993}
}
@inproceedings{Spors2008,
abstract = {Wave field synthesis is a spatial sound field reproduction technique aiming at authentic reproduction of auditory scenes. Its theoretical foundation has been developed almost 20 years ago and has been improved considerably since then. Most of the original work on wave field synthesis is restricted to the reproduction in a planar listening area using linear loudspeaker arrays. Extensions like arbitrarily shaped distributions of secondary sources and three-dimensional reproduction in a listening volume have not been discussed in a unified framework so far. This paper revisits the theory of wave field synthesis and presents a unified theoretical framework covering arbitrarily shaped loudspeaker arrays for two- and three-dimensional repro- duction. The paper additionally gives an overview on the artifacts resulting in practical setups and briefly discusses some extensions to the traditional concepts of WFS.},
address = {Amsterdam, NL},
author = {Spors, Sascha and Rabenstein, Rudolf and Ahrens, Jens},
booktitle = {AES 124th Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Spors, Rabenstein, Ahrens - 2008 - The Theory of Wave Field Synthesis Revisited.pdf:pdf},
isbn = {9781605602950},
pages = {7358},
publisher = {Audio Engineering Society},
title = {{The Theory of Wave Field Synthesis Revisited}},
url = {http://www.deutsche-telekom-laboratories.de/{~}sporssas/publications/2008/AES124{\_}Spors{\_}WFS{\_}Theory.pdf},
year = {2008}
}
@inproceedings{Spors2007,
abstract = {Wave field synthesis (WFS) and higher-order Ambisonics (HOA) are two sound reproduction tech-niques that facilitate a high number of reproduction channels to overcome the sweet-spot limitation known from conventional stereophonic reproduction techniques. HOA is based on a representa-tion of the reproduced wave field in terms of spatial harmonics, WFS is based on the Kirchhoff-Helmholtz integral. It has been shown that HOA and WFS are comparable when applying a near-field correction to HOA and assuming an infinite number of loudspeakers around the listen-ing area. However, both methods diverge with respect to their spatial aliasing properties for a finite number of loudspeakers. This contribution investigates the difference of HOA and WFS in terms of spatial aliasing artifacts for two-dimensional reproduction systems. INTRODUCTION Various massive multichannel reproduction systems have been proposed to enable spatial ren-dering of sound. The best-known of which are wave field synthesis (WFS) and higher-order Ambisonics (HOA). Although both of them are derived on the basis of the wave equation, the approaches come from different directions and their relationship is not clear. The work presented in [3, 5] has revealed a strong connection between WFS and HOA under cer-tain conditions. These conditions are: (1) an infinite number of loudspeakers and (2) a near-field correction for HOA. However, a practical system will only have a limited number of loudspeakers. This might result in spatial aliasing artifacts present in the reproduced wave field. It was already noted in [3] that WFS and HOA show different performance w.r.t. spatial aliasing. Here, we will extend the comparison of WFS and HOA to the behavior of HOA and WFS in terms of their spatial aliasing properties. This paper is organized as follows: We first introduce the theoretical basics of WFS and HOA. We then apply specializations that allow for a comparison of both reproduction techniques. For WFS this specialization is a circular distribution of secondary sources and sampling of the secondary source distribution, for HOA it is a near-field compensation. We will then dedicate a section to the emphasis of the similarities and differences of WFS and HOA with respect to spatial sampling artifacts and illustrate the observations with numerical simulations. Nomenclature We will restrict the descriptions in this paper to two dimensional reproduction. Two dimensional in this context means that an observed sound field is independent from one of the spatial coor-dinates, e.g. P (x, y, z, $\omega$) = P (x, y, $\omega$). The following conventions are used: For scalar variables lower case denotes the time domain, upper case the temporal frequency domain. Vectors are denoted by lower case boldface. The Cartesian and polar coordinate system are used. The},
address = {Madrid, ES},
author = {Spors, Sascha and Ahrens, Jens},
booktitle = {Int. Congr. Acoust.},
file = {:media/francesco/Data/Mega/Mendeley/Spors, Ahrens - 2007 - Comparison of higher order Ambisonics and Wave Field Synthesis with respect to spatial aliasing artifacts.pdf:pdf},
publisher = {ASA},
title = {{Comparison of higher order Ambisonics and Wave Field Synthesis with respect to spatial aliasing artifacts}},
year = {2007}
}
@inproceedings{Spors2013a,
author = {Spors, Sascha and Wierstorf, Hagen},
booktitle = {AIA-DAGA Conf. Acoust.},
file = {:media/francesco/Data/Mega/Mendeley/Spors, Wierstorf - 2013 - A Virtual Endfire Loudspeaker Array for the Generation of Sound Beams.pdf:pdf},
title = {{A Virtual Endfire Loudspeaker Array for the Generation of Sound Beams}},
volume = {40-39},
year = {2013}
}
@article{Nawab1983,
abstract = {We have previously established a number of conditions under which a real signal can be uniquely reconstructed from its STFT magnitude. For the STFT magnitude to be a practical signal representation, we need robust reconstruction algorithms. In this paper, we discuss such a class of algorithms within the framework of sequential extrapolation techniques. Such techniques reconstruct the short-time sections of a signal in an order determined by their positions on the time axis. We find that compared to direct reconstruction, the robust algorithms are less sensitive to roundoff errors. To further test the robustness of these algorithms, we applied them to STFT magnitudes which were purposely modified for accomplishing signal processing tasks such as noise reduction and time-scale modification of speech.},
author = {Nawab, S. and Quatieri, T.},
doi = {10.1109/TASSP.1983.1164162},
file = {:media/francesco/Data/Mega/Mendeley/Nawab, Quatieri - 1983 - Signal reconstruction from short-time Fourier transform magnitude.pdf:pdf},
issn = {0096-3518},
journal = {IEEE Trans. Acoust.},
number = {4},
pages = {986--998},
title = {{Signal reconstruction from short-time Fourier transform magnitude}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1164162},
volume = {31},
year = {1983}
}
@article{Genin1970,
abstract = {Simulation of analogue signals by Laguerre-transformation sampling is considered in the letter. It is shown that the Laguerre transform is more convenient than the Poisson transform for signal analysis; indeed, given the Laguerre transform of a signal, one can immediately write the Laguerre expansion of this signal, while, for the Poisson transform, additional and tedious binomial-weighted summations are required. Also, it is shown that the Laguerre transform corresponds to a simple signal measurement.},
author = {Genin, R. and Calvez, L. C.},
file = {:media/francesco/Data/Mega/Mendeley/Genin, Calvez - 1970 - Laguerre-Transform signal analysis.pdf:pdf},
journal = {IEEE Electron. Lett.},
number = {18},
pages = {587 -- 588},
title = {{Laguerre-Transform signal analysis}},
volume = {6},
year = {1970}
}
@inproceedings{Annibale2011,
abstract = {SCENIC is an EC-funded project aimed at developing a harmonized corpus of methodologies for environment- aware acoustic sensing and rendering. The project focusses on space-time acoustic processing solutions that do not just accommodate the environment in the modeling process but that make the environment help towards achieving the goal at hand. The solutions developed within this project cover a wide range of applications, including acoustic self-calibration, aimed at estimating the parameters of the acoustic system; environment inference, aimed at identifying and characterizing all the relevant acoustic reflectors in the environment. The information gathered through such steps is then used to boost the performance of wavefield rendering methods as well as source localization/characterization/extraction in reverberant environments.},
address = {New York, NY, USA},
author = {Annibale, Paolo and Antonacci, Fabio and Bestagini, Paolo and Brutti, Alessio and Canclini, Antonio and Cristoferetti, L. and Habets, Emanu{\"{e}}l A. P. and Filos, Jason and Kellermann, Walter and Kowalczyk, Konrad and Lombard, Anthony and Mabande, Edwin and Markovi{\'{c}}, Dejan and Naylor, Patrick A. and Omologo, Maurizio and Rabenstein, Rudolf and Sarti, Augusto and Svaizer, Piergiorgio and Thomas, Mark R. P.},
booktitle = {AES 131st Conv.},
file = {:media/francesco/Data/Mega/Mendeley/Annibale et al. - 2011 - The SCENIC Project Space-Time Audio Processing for Environment-Aware Acoustic Sensing and Rendering.pdf:pdf},
isbn = {9781618393968},
publisher = {Audio Engineering Society},
title = {{The SCENIC Project: Space-Time Audio Processing for Environment-Aware Acoustic Sensing and Rendering}},
year = {2011}
}
@article{Gerzon1973,
abstract = {Periphony (sound reproduction in both vertical and horizontal directions around a listener) may be recorded among others, via practical two-, four-, and nine-channel systems. Matrix parameters and microphone techniques are described for 19 different systems, and a design procedure for other periphonic systems is given. Amplitude and energy directional resolution are discussed, as is compatibility with current horizontal-only systems.},
author = {Gerzon, Michael A},
file = {:media/francesco/Data/Mega/Mendeley/Gerzon - 1973 - Periphony With-Height Sound Reproduction.pdf:pdf},
issn = {00047554},
journal = {J. Audio Eng. Soc.},
keywords = {Aud,HOA},
number = {1},
pages = {2--10},
title = {{Periphony: With-Height Sound Reproduction}},
volume = {21},
year = {1973}
}
@article{Bianchi2016,
abstract = {Soundfield imaging is a special analysis methodology aimed at capturing the directional components of the acoustic field and mapping them onto a domain called “ray space”, where rele- vant acoustic objects become linear patterns, i.e., sets of collinear points. This allows us to overcome resolution issues while easing far-field assumptions. In this paper, we generalize this concept by introducing the ray space transform for acoustic field repre- sentation. The transform is based on a short space-time Fourier transform of the signals captured by a microphone array, using discrete Gabor frames. The resulting transform coefficients are parameterized in the same ray space used for soundfield imaging. The resulting transform enables the definition of analysis and syn- thesis operators, which exhibit perfect reconstruction capabilities. We show examples of applications of the ray space transform to source localization and spot spatial filtering},
author = {Bianchi, Lucio and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
doi = {10.1109/TSP.2016.2591500},
file = {:media/francesco/Data/Mega/Mendeley/Bianchi et al. - 2016 - The ray space transform A new framework for wave field processing.pdf:pdf},
isbn = {1053-587X VO - 64},
issn = {1053587X},
journal = {IEEE Trans. Signal Process.},
keywords = {Array signal processing,near-field spatial filtering,plenacoustic function,sound field analysis,source localization,space-time analysis,wave field processing},
number = {21},
pages = {5696--5706},
title = {{The ray space transform: A new framework for wave field processing}},
volume = {64},
year = {2016}
}
@inproceedings{Bianchi2014,
abstract = {In this paper we propose a robust beamforming technique which takes into account uncertainties and variations in the radiation pattern of the loudspeakers. The proposed technique is based on the solution of a robust least-square problem in which the propagation matrix is to some extent unknown. Both simulations and experimental results prove the validity of the proposed methodology in terms of directivity index and white noise gain.},
author = {Bianchi, Lucio and Magalotti, Roberto and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
doi = {10.1109/ICASSP.2014.6854443},
file = {:media/francesco/Data/Mega/Mendeley/Bianchi et al. - 2014 - Robust beamforming under uncertainties in the loudspeakers directivity pattern.pdf:pdf},
isbn = {9781479928927},
issn = {15206149},
keywords = {Loudspeaker array,radiation pattern,regularization,robust beamforming,robust least-squares},
pages = {4448--4452},
title = {{Robust beamforming under uncertainties in the loudspeakers directivity pattern}},
year = {2014}
}
@inproceedings{Bianchi2013a,
abstract = {In this paper we present a technique for the rendering of directional sources by means of loudspeaker arrays. The proposed methodology is based on a decomposition of the sound field in terms of plane waves. Within this framework the directivity of the source is naturally included in the rendering problem, therefore accommodating the directivity into the picture becomes much simpler. For this purpose, the loudspeaker array is subdivided into overlapping sub-arrays, each generating a plane wave component. The individual plane waves are then weighed by the desired directivity pattern. Simulations and experimental results show that the proposed technique is able to reproduce the sound field of directional sources with an improved accuracy with respect to existing techniques.},
address = {Pula, IT},
author = {Bianchi, Lucio and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {IEEE Int. Work. Multimed. Signal Process.},
doi = {10.1109/MMSP.2013.6659256},
file = {:media/francesco/Data/Mega/Mendeley/Bianchi et al. - 2013 - Rendering of directional sources through loudspeaker arrays based on plane wave decomposition.pdf:pdf},
isbn = {9781479901258},
pages = {13--18},
publisher = {IEEE},
title = {{Rendering of directional sources through loudspeaker arrays based on plane wave decomposition}},
year = {2013}
}
@article{Bianchi2016a,
abstract = {In this manuscript we propose an analytic solution to the problem of sound field rendering, based on the plane wave decomposition, which is here derived with reference to the Herglotz density function. The plane wave decomposition encodes the directional contributions to the sound field, and allows us to describe elementary sound fields in a model-based fashion, parameterized only by the source location. We show how this representation can be exploited for rendering purposes using a wide variety of loudspeaker arrangements. We start by deriving closed-form expressions for the loudspeaker weights based on the plane wave decomposition and we validate this derivation with an analysis of the reproduction error for the case of a circular array of speakers. We then show how to extend the proposed method to non-circular geometries. We assess the performance of the proposed rendering solution for various array configurations, offering a comparison with state-of-the-art analytical rendering techniques.},
author = {Bianchi, Lucio and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
doi = {10.1016/j.apacoust.2015.10.010},
file = {:media/francesco/Data/Mega/Mendeley/Bianchi et al. - 2016 - Model-based acoustic rendering based on plane wave decomposition.pdf:pdf},
issn = {1872910X},
journal = {Appl. Acoust.},
keywords = {Loudspeaker arrays,Plane wave decomposition,Sound field rendering,Spatial audio},
pages = {127--134},
title = {{Model-based acoustic rendering based on plane wave decomposition}},
volume = {104},
year = {2016}
}
@inproceedings{Bianchi2013,
abstract = {In this paper we propose a methodology aimed at improving the resolution capabilities of plenacoustic imaging, which is based on deconvolution techniques mutuated from aerospace acoustic imaging. In order to reduce the computational burden, we also propose a modification of the minimization problem that exploits the highly structured information contained in the plenacoustic image. Experiments and simulations show the improvement of the accuracy gained by applying the deconvolution operator.},
address = {New Paltz, NY, USA},
author = {Bianchi, Lucio and Markovi{\'{c}}, Dejan and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {IEEE Work. Appl. Signal Process. to Audio Acoust.},
doi = {10.1109/WASPAA.2013.6701850},
file = {:media/francesco/Data/Mega/Mendeley/Bianchi et al. - 2013 - Deconvolution of plenacoustic images.pdf:pdf},
isbn = {9781479909728},
keywords = {Plenacoustic imaging,acoustic imaging,deconvolution,microphone array},
publisher = {IEEE},
title = {{Deconvolution of plenacoustic images}},
year = {2013}
}
@inproceedings{Bianchi2016b,
abstract = {In the process of soundfield imaging, as defined in the literature, a microphone array is subdivided into overlapping sub-arrays and soundfield images are obtained by juxtaposition of spatial spectra computed from individual subarray data. In this paper we show that the whole process can be conveniently seen as a linear transformation applied to array data. This linear transformation embeds a nonlinear mapping to cast the directional information in a more convenient domain: the ray space. We show by simulations that the proposed formulation is suitable for fast implementation of the soundfield imag-ing operation, and, more specifically, for the localization of acoustic sources.},
address = {Shangai, CN},
author = {Bianchi, Lucio and Baldini, Anastasio V. and Markovi{\'{c}}, Dejan and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {IEEE Int. Conf. Acoust. Speech Signal Process.},
doi = {10.1109/ICASSP.2016.7471707},
file = {:media/francesco/Data/Mega/Mendeley/Bianchi et al. - 2016 - A linear operator for the computation of soundfield maps.pdf:pdf},
isbn = {9781479999880},
keywords = {Index Terms— Microphone arrays,array signal processing,plenacoustic function,ray space,soundfield imaging},
pages = {410--414},
publisher = {IEEE},
title = {{A linear operator for the computation of soundfield maps}},
year = {2016}
}
@inproceedings{Pekonen2009,
abstract = {A recently introduced structure to implement a continuously smooth spectral delay, based on a cascade of first-order allpass filters and an equalizing filter, is described and the properties of this spectral delay filter are reviewed. A new amplitude envelope equalizing filter for the spectral delay filter is proposed and the properties of structures utilizing feedback and/or time-varying filter coefficients are discussed. In addition, the stability conditions for the feed- back and the time-varying structures are derived. A spectral delay filter can be used for synthesizing chirp-like sounds or for modify- ing the timbre of arbitrary audio signals. Sound examples on the use of the spectral delay filters utilizing the structures discussed in this paper can be found at http://www.acoustics.hut. fi/publications/papers/dafx09-sdf/.},
address = {Como, IT},
author = {Pekonen, Jussi and V{\"{a}}lim{\"{a}}ki, Vesa and Abel, Jonathan S. and Smith, Julius O.},
booktitle = {Interational Conf. Digit. Audio Eff.},
file = {:media/francesco/Data/Mega/Mendeley/Pekonen et al. - 2009 - Spectral delay filters with feedback and time-varying coefficients.pdf:pdf},
number = {1},
pages = {1--8},
title = {{Spectral delay filters with feedback and time-varying coefficients}},
url = {http://www.acoustics.hut.},
volume = {1},
year = {2009}
}
@inproceedings{Daniel2003,
abstract = {Ambisonics and Wavefield Synthesis are two ways of rendering 3D audio, which both aim at physically reconstructing the sound field. Though they derive from distinct theoretical fundamentals, they have already been shown as equivalent under given assumptions. This paper further discusses their relationship by introducing new results regarding the coding and rendering of finite distance and enclosed sources. An updated view of the current knowledge is first given. A unified analysis of sound pickup and reproduction by mean of concentric transducer arrays then provides an insight into the spatial encoding and decoding properties. While merging the analysis tools of both techniques and investigating them on a common ground, general compromises are highlighted in terms of spatial aliasing, error and noise amplification. supplies},
address = {Amsterdam, NL},
author = {Daniel, J{\'{e}}r{\^{o}}me and Nicol, Rozenn and Moreau, S{\'{e}}bastien},
booktitle = {AES 114th Conv.},
doi = {10.1.1.459.117},
file = {:media/francesco/Data/Mega/Mendeley/Daniel, Nicol, Moreau - 2003 - Further investigations of high order ambisonics and wavefield synthesis for holophonic sound imaging.pdf:pdf},
publisher = {Audio Engineering Society},
title = {{Further investigations of high order ambisonics and wavefield synthesis for holophonic sound imaging}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=12567},
year = {2003}
}
@article{Kovacevic2007,
abstract = {While the first part of this article presented most of the basic theoretical developments of frames, this part is more user friendly. It covers a large number of known frame families (harmonic tight frames, equiangular frames, unit-norm tight frame, Gabor frames, cosine-modulated frames, double-density frames, multidimensional frames, filter bank frame) as well as those applications where frames made a difference.},
author = {Kova{\v{c}}evi{\'{c}}, Jelena and Chebira, Amina},
doi = {10.1109/MSP.2007.904809},
file = {:media/francesco/Data/Mega/Mendeley/Kova{\v{c}}evi{\'{c}}, Chebira - 2007 - Life beyond bases The advent of frames (Part II).pdf:pdf},
isbn = {1053-5888},
journal = {IEEE Signal Process. Mag.},
title = {{Life beyond bases: The advent of frames (Part II)}},
year = {2007}
}
@article{Kovacevic2007a,
author = {Kova{\v{c}}evi{\'{c}}, Jelena and Chebira, Amina},
file = {:media/francesco/Data/Mega/Mendeley/Kova{\v{c}}evi{\'{c}}, Chebira - 2007 - Life beyond bases The advent of frames (Part I).pdf:pdf},
journal = {IEEE Signal Process. Mag.},
keywords = {Air traffic control,Air transportation,Clouds,Meteorology,Radar signal processing,Remote sensing,Spaceborne radar,Volcanic ash},
title = {{Life beyond bases: The advent of frames (Part I)}},
volume = {86},
year = {2007}
}
@article{Liu1992,
abstract = {A finite impulse response (FIR) filter that can synthesize any$\backslash$nfractional sample delay by a nonlinear interpolation technique is$\backslash$npresented. Analytically closed-form solutions for the tap weights of$\backslash$nsuch an FIR filter and their frequency responses are also$\backslash$npresented},
author = {Liu, Ging Shing and Wei, Che Ho},
doi = {10.1109/82.205818},
file = {:media/francesco/Data/Mega/Mendeley/Liu, Wei - 1992 - A New Variable Fractional Sample Delay Filter with Nonlinear Interpolation.pdf:pdf},
isbn = {0-7803-0050-5},
issn = {10577130},
journal = {IEEE Trans. Circuits Syst. II Analog Digit. Signal Process.},
number = {2},
pages = {123--126},
title = {{A New Variable Fractional Sample Delay Filter with Nonlinear Interpolation}},
volume = {39},
year = {1992}
}
@inproceedings{Borra2017,
abstract = {In this paper we present a source extraction technique for multiple uniform linear arrays distributed in space. The technique adopts the Ray Space Transform representation of the sound field, which is inherently based on the Plane Wave Decomposition. The Ray Space Transform gives us an intuitive representation of the acoustic field, thus enabling the adoption of geometrically-motivated constraints in the spatial filter design. The proposed approach is semi-blind since it needs as input an estimate of the source positions. We prove the effectiveness of the proposed solution through simulations using both white noise and speech signals.},
address = {San Francisco, CA, USA},
author = {Borra, Federico and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {Hands-free Speech Commun. Microphone Arrays (HSCMA), 2017},
doi = {10.1109/HSCMA.2017.7895579},
file = {:media/francesco/Data/Mega/Mendeley/Borra et al. - 2017 - Extraction of acoustic sources for multiple arrays based on the Ray Space Transform.pdf:pdf},
keywords = {Microphone array,Ray Space Transform,near-field beamforming,source extraction},
mendeley-tags = {Microphone array,Ray Space Transform,near-field beamforming,source extraction},
pages = {146 -- 150},
publisher = {IEEE},
title = {{Extraction of acoustic sources for multiple arrays based on the Ray Space Transform}},
year = {2017}
}
@article{Gabor1946,
abstract = {Hitherto communication theory was based on two alternative methods of signal analysis. One is the description of the signal as a function of time; the other is Fourier analysis. Both are idealizations, as the first method operates with sharply defined instants of time, the second with infinite wave-trains of rigorously defined frequencies. But our everyday experiences{\^{A}}¿especially our auditory sensations{\^{A}}¿insist on a description in terms of both time and frequency. In the present paper this point of view is developed in quantitative language. Signals are represented in two dimensions, with time and frequency as co-ordinates. Such two-dimensional representations can be called {\^{A}}¿information diagrams,{\^{A}}¿ as areas in them are proportional to the number of independent data which they can convey. This is a consequence of the fact that the frequency of a signal which is not of infinite duration can be defined only with a certain inaccuracy, which is inversely proportional to the duration, and vice versa. This {\^{A}}¿uncertainty relation{\^{A}}¿ suggests a new method of description, intermediate between the two extremes of time analysis and spectral analysis. There are certain {\^{A}}¿elementary signals{\^{A}}¿ which occupy the smallest possible area in the information diagram. They are harmonic oscillations modulated by a {\^{A}}¿probability pulse.{\^{A}}¿ Each elementary signal can be considered as conveying exactly one datum, or one {\^{A}}¿quantum of information.{\^{A}}¿ Any signal can be expanded in terms of these by a process which includes time analysis and Fourier analysis as extreme cases. These new methods of analysis, which involve some of the mathematical apparatus of quantum theory, are illustrated by application to some problems of transmission theory, such as direct generation of single sidebands, signals transmitted in minimum time through limited frequency channels, frequency modulation and time-division multiplex telephony.},
author = {Gabor, Dennis},
doi = {10.1049/ji-3-2.1946.0074},
file = {:media/francesco/Data/Mega/Mendeley/Gabor - 1946 - Theory of communication. Part 1 The analysis of information.pdf:pdf},
issn = {2054-0604},
journal = {J. Inst. Electr. Eng. - Part III Radio Commun. Eng.},
number = {26},
pages = {429--441},
title = {{Theory of communication. Part 1: The analysis of information}},
url = {http://digital-library.theiet.org/content/journals/10.1049/ji-3-2.1946.0074},
volume = {93},
year = {1946}
}
@inproceedings{Markovic2012,
abstract = {In this work we present a novel approach to acoustic scene analy-sis with microphone arrays. Acoustic measurements are here rep-resented in the ray space, which is defined as the space of param-eters that describe acoustic rays. The ray space can be thought of as the domain of the plenacoustic function, which defines the sound pressure field in all positions in space. We discuss sampling and distortion with respect to the ideal plenacoustic function introduced using a microphone array. Plenacoustic images can potentially be used for environment inference, source characterization and wave-field extrapolation.},
address = {Aachen, DE},
author = {Markovi{\'{c}}, Dejan and Sandrini, G and Antonacci, Fabio and Sarti, Augusto and Tubaro, Stefano},
booktitle = {IEEE Int. Work. Acoust. Signal Enhanc.},
file = {:media/francesco/Data/Mega/Mendeley/Markovi{\'{c}} et al. - 2012 - Plenacoustic Imaging in the Ray Space.pdf:pdf},
keywords = {Index Terms— Plenacoustic function,acoustic images},
publisher = {IEEE},
title = {{Plenacoustic Imaging in the Ray Space}},
url = {http://ieeexplore.ieee.org/document/6309429/},
year = {2012}
}
