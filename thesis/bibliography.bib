@inproceedings{feng2003popular,
abstract = {In the community of music information retrieval, researchers developed methods to retrieval music with a particular melody, they also developed methods to retrieval music by similarity. We aim to retrieval music by mood, which is sometimes the exclusive manner people select music to enjoy, for example, when someone is sad for some reason, she or he wants to listen to a piece of music that can cheer her or him up, at this moment she or he will search music segment by mood no matter what the melody sounds and which the piece of music is similar to. In the essence, the difficulty for music retrieval by mood stems from the gap between the rich meanings that users want when they query and the shallowness of content descriptor we can actually compute.},
address = {Hangzhou, China},
author = {Feng, Yazhong and Zhuang, Yueting and Pan, Yunhe},
title = {{Popular music retrieval by detecting mood}},
booktitle={Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval},
pages = {375--376},
year = {2003}
}
@book{yang2011music,
  title={Music emotion recognition},
  author={Yang, Yi-Hsuan and Chen, Homer H},
  year={2011},
  publisher={CRC Press, Inc.},
  address = {USA},
  edition = {1st} ,
  isbn = {9781439850466}
}
@inproceedings{lee2004survey,
  title={Survey of music information needs, uses, and seeking behaviours: preliminary findings.},
  author={Lee, Jin Ha and Downie, J Stephen},
  booktitle={ISMIR},
  volume={2004},
  pages={5th},
  year={2004},
  organization={Citeseer}
}
@article{juslin2004expression,
  title={Expression, perception, and induction of musical emotions: A review and a questionnaire study of everyday listening},
  author={Juslin, Patrik N and Laukka, Petri},
  journal={Journal of new music research},
  volume={33},
  number={3},
  pages={217--238},
  year={2004},
  publisher={Taylor \& Francis}
}
@inproceedings{van2006emotion,
  title={Emotion detection in music, a survey},
  author={Van De Laar, Bram},
  booktitle={Twente Student Conference on IT},
  volume={1},
  pages={700},
  year={2006}
}
@article{hevner1935expression,
  title={Expression in music: a discussion of experimental studies and theories.},
  author={Hevner, Kate},
  journal={Psychological review},
  volume={42},
  number={2},
  pages={186},
  year={1935},
  publisher={Psychological Review Company}
}
@article{russell1980circumplex,
  title={A circumplex model of affect.},
  author={Russell, James A},
  journal={Journal of personality and social psychology},
  volume={39},
  number={6},
  pages={1161},
  year={1980},
  publisher={American Psychological Association}
}
@article{macdorman2007automatic,
  title={Automatic emotion prediction of song excerpts: Index construction, algorithm design, and empirical comparison},
  author={MacDorman, Stuart Ough Chin-Chang Ho, Karl F},
  journal={Journal of New Music Research},
  volume={36},
  number={4},
  pages={281--299},
  year={2007},
  publisher={Taylor \& Francis}
}







@book{Suzuki2011,
abstract = {This paper summarizes my 40 years of research on speech and speaker recognition, focusing on selected topics that I have investigated at NTT Laboratories, Bell Laboratories and Tokyo Institute of Technology with my colleagues and students. These topics include: the importance of spectral dynamics in speech perception; speaker recognition methods using statistical features, cepstral features, and HMM/GMM; text-prompted speaker recognition; speech recognition using dynamic features; Japanese LVCSR; robust speech recognition; spontaneous speech corpus construction and analysis; spontaneous speech recognition; automatic speech summarization; and WFST-based decoder development and its applications.},
address = {Singapore, SG},
author = {Suzuki, Yoiti and Brungart, D and Kato, H and Iida, K and Suzuku, Y},
booktitle = {Recherche},
doi = {10.1142/7674},
edition = {1st},
isbn = {9789814299312},
publisher = {World Scientific},
title = {{Principles and Applications of Spatial Hearing}},
url = {http://www.amazon.com/Principles-Applications-Spatial-Hearing-Suzuki/dp/9814313874},
year = {2011}
}

@techreport{AES2008,
abstract = {This standard describes how the measurements of loudspeaker polar radiation data shall be made and documented. This acquired data is suitable for application in room acoustic, electro-acoustic, and sound system predictions, and loudspeaker data sheets.},
address = {New York, NY, USA},
booktitle = {AES Stand.},
file = {:media/francesco/Data/Mega/Mendeley/Unknown - 2008 - AES Standards on Acoustics - Sound Source Modeling - Loudspeaker Polar Radiation Measurements.pdf:pdf},
number = {Reaffirmed},
publisher = {Audio Engineering Society},
title = {{AES Standards on Acoustics - Sound Source Modeling - Loudspeaker Polar Radiation Measurements}},
volume = {2014},
year = {2008}
}
@inproceedings{Tohyama1989,
abstract = {Sound power output from a source can be reduced in a closed space by using secondary sources. The minimum power response (MPR) from sound sources is analyzed based on the modal theory. It is shown that the MPR can be approximately described using the modal overlap properties. The power reduction is confirmed experimentally for a pure tone source in a large reverberation room. The corner method for sensor location is also discussed.},
address = {Glasgow, UK},
author = {Tohyama, Mikio and Suzuki, Akira and Sugiyama, Kiyoshi},
booktitle = {IEEE Int. Conf. Acoust. Speech, Signal Process.},
doi = {https://doi.org/10.1109/ICASSP.1989.266860},
file = {:media/francesco/Data/Mega/Mendeley/Tohyama, Suzuki, Sugiyama - 1989 - Active Power Minimization of a Sound Source in a Reverberant Space.pdf:pdf},
pages = {2037--2040},
publisher = {IEEE},
title = {{Active Power Minimization of a Sound Source in a Reverberant Space}},
year = {1989}
}
@article{Pulkki2007,
abstract = {Directional audio coding (DirAC) is a method for spatial sound representation, applicable for different sound reproduction systems. In the analysis part the diffuseness and direction of arrival of sound are estimated in a single location depending on time and frequency. In the synthesis part microphone signals are first divided into nondiffuse and diffuse parts, and are then reproduced using different strategies. DirAC is developed from an existing technology for impulse response reproduction, spatial impulse response rendering (SIRR), and imple- mentations of DirAC for different applications are described.},
author = {Pulkki, Ville},
file = {:media/francesco/Data/Mega/Mendeley/Pulkki - 2007 - Spatial sound reproduction with directional audio coding.pdf:pdf},
issn = {0004-7554},
journal = {J. Audio Eng. Soc.},
number = {6},
pages = {503--516},
pmid = {34447274778},
title = {{Spatial sound reproduction with directional audio coding}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=14170},
volume = {55},
year = {2007}
}