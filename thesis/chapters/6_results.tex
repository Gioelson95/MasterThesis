\chapter{Results}
\label{chap:Improvements}
\pagestyle{plain}
\vspace{0.5cm}

\noindent In this chapter we present as first \gls{pmemo} results and performances, then we will show how our sistem perform based on different feature selection methods and different \gls{ml} regression methods.

\section{PMEmo performances}
In the article, they adopt \gls{mlr} and \gls{svr} as the base classifiers to model emotions in valence and arousal.
\\
For the static part, they trained and tested the classifiers using all the $6373$-dimension features $x_1,x_2,...,x_{6373}$ and separate static labels of valence $y_{valence}$ and arousal $y_{arousal}$ respectively.
\begin{equation}
	{X_1,X_2,...,X_m} \quad \rightarrow \quad {e_1,e_2,...,e_m}
\end{equation}
where:
\begin{itemize}
	\item $m$ is the number of songs
	\item $X_i={x_1,x_2,...,x_{6373}}$ is the feature set of the $i^{th}$ song
	\item $e_i$ is the value of valence or arousal for this song
\end{itemize}
With respect of continuous mood of a song, is natural to consider a decoupling into two scales and then recognize them separately.
\\
For the dynamic emotion, defined as:
\begin{equation}
	L_i=\bar{L}_i+D_i^{t_i}
\end{equation}
where:
\begin{itemize}
	\item $t_i$ is the number of timestamps in the $i^{th}$ song
	\item $\bar{L}_i$ is the mean of dynamic emotion
	\item $D_i^{t_i}$ is the fluctuation at each timestamp
\end{itemize}
the global model is:
\begin{equation}
	{X_1,X_2,...,X_m} \quad \rightarrow \quad {\bar{L}_1,\bar{L}_2,...,\bar{L}_m}
\end{equation}
while, the local model is:
\begin{equation}
	{Y_1^{t_1},Y_2^{t_2},...,Y_m^{t_m}} \quad \rightarrow \quad {D_1^{t_1},D_2^{t_2},...,D_m^{t_m}}
\end{equation}
where:
\begin{itemize}
	\item $m$ is the number of songs
	\item $X_i$ is the global feature set of it
	\item $Y_i^{t_i}$ is a matrix of 260 columns and $t_i$ rows
\end{itemize}
Before the regression models, they resized all the annotations (both for static and dynamic annotations) into $[0,1]$.
\\ \indent
Static task is to predict the overall emotion of a whole song, represented by a single valence value and arousal value. To train and test, they divided the dataset in $11$ folds, 10 constituted the training set and the remaining set used to test the train model. A 10-fold-cross-validation was used for parameter optimization.
\\
\gls{rmse} and Pearson Correlation Coefficient (r) were calculated separately for valence and arousal. In table \ref{table:PMEmo_results_static} is shown results on static emotions.
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		Dimension & Classifier & RMSE & r \\ [0.5ex] 
		\hline\hline Valence & MLR & 0.136 & 0.546 \\ 
		\hline Valence & SVR & 0.124 & 0.638 \\
		\hline Arousal & MLR & 0.111 & 0.719 \\
		\hline Arousal & SVR & 0.102 & 0.764 \\
		\hline
	\end{tabular}
	\caption{Evaluation results on static emotions}
	\label{table:PMEmo_results_static}
\end{table}
\\
About the dynamic case, a hierarchical regression model aiming to recognize the global trend as well as local variation was built. For Global-scale they extracted, for each song, one global feature and mapped it into one global emotion. For Local-scale operation, for each song, they divided it into $1s$ segment with $50\%$ overlap, then extracting the local features from these fragments and project them onto mood space.
\\
In table \ref{table:PMEmo_results_dynamic} is presented the evaluation results on dynamic emotions.
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Dimension & Classifier & Scale & RMSE & r \\ [0.5ex] 
		\hline\hline Valence & MLR & global & 0.103 & 0.673 \\
		\hline Valence & MLR & local & 0.016 & 0.047 \\
		\hline Valence & SVR & global & 0.106 & 0.675 \\
		\hline Valence & SVR & local & 0.016 & 0.095 \\
		\hline Arousal & MLR & global & 0.113 & 0.816 \\
		\hline Arousal & MLR & local & 0.020 & 0.103 \\
		\hline Arousal & SVR & global & 0.101 & 0.844 \\
		\hline Arousal & SVR & local & 0.019 & 0.115 \\
		\hline
	\end{tabular}
	\caption{Evaluation results on dynamic emotions}
	\label{table:PMEmo_results_dynamic}
\end{table}
\\
In \gls{pmemo} work, as already mentioned, they also recorded \gls{eda} subjects data when they were listening to music.
\\
On \gls{eda}, they employed a low-pass filter of $0.6Hz$ to diminish the noise due to motion artifacts. Then skin electric conductance was scaled in z-score:
\begin{equation}
	z-score=\dfrac{X-\mu}{\sigma}
\end{equation}
where $\mu$ is the mean of vector $X$ and $\sigma$ is the standard variation.
Last passage on \gls{eda} signal was to resample them, from $50Hz$ to $2Hz$ due to different acquisition of EDA and continuous emotions.
\\
They trained and tested \gls{mlr} and \gls{svr} with pre-processed \gls{eda} data in the dynamic case and results are shown in table \ref{table:PMEmo_results_EDA}.
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Dimension & Classifier & Scale & RMSE & r \\ [0.5ex] 
		\hline\hline Valence & MLR & global & 0.139 & 0.063 \\
		\hline Valence & MLR & local & 0.016 & 0.060 \\
		\hline Valence & SVR & global & 0.141 & 0.017 \\
		\hline Valence & SVR & local & 0.016 & 0.059 \\
		\hline Arousal & MLR & global & 0.186 & 0.011 \\
		\hline Arousal & MLR & local & 0.019 & 0.097 \\
		\hline Arousal & SVR & global & 0.194 & 0.040 \\
		\hline Arousal & SVR & local & 0.019 & 0.099 \\
		\hline
	\end{tabular}
	\caption{Evaluation results on dynamic EDA}
	\label{table:PMEmo_results_EDA}
\end{table}

\section{Our model performances}
In this section are presented all the results acquired with different parameters, with and without feature selection, different data types and different regressors.

\subsection{No feature selection}
Here, in table \ref{table:audio_no_fs} are shown the results for audio data, where no feature selection algorithm has been applied. In the tables, are highlighted the best results for every dimension, one for the \gls{rmse} and one for r2.
\\
\begin{table}[h!]
\begin{adjustwidth}{-3cm}{-1cm}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline \multicolumn{11}{|c|}{Arousal (mean) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.102 & 0.184 & 0.184 & \cellcolor{yellow}0.100 & 0.119 & 0.113 & 0.209 & 0.106 & 0.129 & 0.136 \\
		\hline R2 & \cellcolor{yellow}0.669 & -0.039 & -0.039 & 0.680 & 0.558 & 0.606 & -1.115 & 0.644 & 0.477 & 0.459 \\
		\hline \hline  \multicolumn{11}{|c|}{Valence (mean) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.122 & 0.162 & 0.162 & 0.120 & 0.126 & \cellcolor{yellow}0.119 & 0.211 & 0.127 & 0.143 & 0.127 \\
		\hline R2 & 0.373 & -0.056 & -0.056 & 0.400 & 0.357 & \cellcolor{yellow}0.418 & -2.233 & 0.333 & 0.148 & 0.356 \\
		\hline \hline  \multicolumn{11}{|c|}{Arousal (std) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.047 & 0.047 & 0.047 & \cellcolor{yellow}0.046 & 0.047 & 0.050 & 0.050 & 0.049 & 0.051 & 0.045 \\
		\hline R2 & 0.007 & -0.013 & -0.013 & 0.051 & -0.009 & -0.143 & -0.123 & -0.097 & -0.184 & \cellcolor{yellow}0.136 \\
		\hline \hline  \multicolumn{11}{|c|}{Valence (std) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.051 & \cellcolor{yellow}0.046 & \cellcolor{yellow}0.046 & 0.051 & 0.049 & 0.047 & 0.048 & 0.048 & 0.052 & 0.045 \\
		\hline R2 & -0.349 & -0.026 & -0.026 & -0.334 & -0.187 & -0.071 & -0.136 & -0.104 & -0.397 & \cellcolor{yellow}-0.011 \\		
		\hline
	\end{tabular}
	\end{adjustwidth}
	\caption{No feature selection for audio data, with RMSE and r2 score}
	\label{table:audio_no_fs}
\end{table}
\\
Here, in table \ref{table:eda_no_fs} are shown the results for \gls{eda} data, where no feature selection algorithm has been applied.
\\
\begin{table}[h!]
\begin{adjustwidth}{-3cm}{-1cm}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline \multicolumn{11}{|c|}{Arousal (mean) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.188 & 0.184 & 0.184 & 0.182 & 0.136 & 0.074 & 0.096 & 0.055 & \cellcolor{yellow}0.018 & 0.182 \\
		\hline R2 & 0.560 & -0.039 & -0.039 & 0.515 & 0.435 & \cellcolor{yellow}0.831 & 0.685 & 0.807 & 0.800 & 0.019 \\
		\hline \hline  \multicolumn{11}{|c|}{Valence (mean) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.163 & 0.162 & 0.162 & 0.170 & 0.121 & 0.073 & 0.100 & 0.053 & \cellcolor{yellow}0.018 & 0.158 \\
		\hline R2 & 0.500 & -0.056 & -0.056 & 0.416 & 0.410 & 0.780 & 0.480 & \cellcolor{yellow}0.886 & 0.855 & -0.006 \\
		\hline \hline  \multicolumn{11}{|c|}{Arousal (std) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.047 & 0.047 & 0.047 & 0.047 & 0.035 & 0.048 & 0.048 & 0.045 & \cellcolor{yellow}0.044 & 0.046 \\
		\hline R2 & -0.013 & -0.013 & -0.013 & 0.011 & \cellcolor{yellow}0.439 & -0.072 & -0.042 & 0.067 & 0.070 & 0.035 \\
		\hline \hline  \multicolumn{11}{|c|}{Valence (std) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.046 & 0.046 & 0.046 & 0.046 & 0.035 & 0.045 & 0.045 & 0.43 & \cellcolor{yellow}0.030 & 0.044 \\
		\hline R2 & -0.025 & -0.026 & -0.026 & 0.205 & \cellcolor{yellow}0.406 & 0.015 & 0.012 & 0.101 & 0.101 & 0.026 \\
		\hline
	\end{tabular}
	\end{adjustwidth}
	\caption{No feature selection for EDA data, with RMSE and r2 score}
	\label{table:eda_no_fs}
\end{table}
\\
In table \ref{table:fusion_no_fs} are shown the results for fusion data, given by the union of audio and \gls{eda} features, where no feature selection algorithm has been applied.
\begin{table}[h!]
\begin{adjustwidth}{-3cm}{-1cm}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline \multicolumn{11}{|c|}{Arousal (mean) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.109 & 0.184 & 0.184 & \cellcolor{yellow}0.103 & 0.126 & 0.110 & 0.139 & 0.112 & 0.131 & 0.147 \\
		\hline R2 & 0.622 & -0.039 & -0.039 & 0.621 & 0.510 & \cellcolor{yellow}0.769 & 0.346 & 0.599 & 0.465 & 0.332 \\
		\hline \hline  \multicolumn{11}{|c|}{Valence (mean) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.134 & 0.162 & 0.162 & 0.127 & 0.329 & \cellcolor{yellow}0.645 & 0.448 & 0.138 & 0.142 & 0.137 \\
		\hline R2 & 0.243 & -0.056 & -0.056 & 0.322 & 0.333 & \cellcolor{yellow}0.389 & -0.014 & 0.204 & 0.162 & 0.244 \\
		\hline \hline  \multicolumn{11}{|c|}{Arousal (std) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.052 & 0.047 & 0.047 & 0.049 & \cellcolor{yellow}0.046 & 0.050 & 0.050 & 0.049 & 0.051 & 0.045 \\
		\hline R2 & -0.222 & -0.013 & -0.013 & -0.101 & 0.027 & -0.160 & -0.159 & -0.090 & -0.223 & 0.081 \\
		\hline \hline  \multicolumn{11}{|c|}{Valence (std) dimension} \\
		\hline & LR & Lasso & ElasticNet & Ridge & kNN & SVRrbf & SVRpoly & SVRlinear & DT & RF \\
		\hline RMSE & 0.056 & \cellcolor{yellow}0.046 & \cellcolor{yellow}0.046 & 0.053 & 0.048 & 0.047 & 0.048 & 0.052 & 0.052 & 0.046 \\
		\hline R2 & -0.547 & -0.026 & -0.026 & -0.410 & -0.140 & -0.087 & -0.115 & -0.116 & -0.356 & \cellcolor{yellow}-0.009 \\
		\hline
	\end{tabular}
	\end{adjustwidth}
	\caption{No feature selection for fusion data, with RMSE and r2 score}
	\label{table:fusion_no_fs}
\end{table}
\newpage
\subsection{Feature selection}
After getting results from the three set of data, audio, \gls{eda} and fusion with all the features, we implemented all the feature selection algorithms already explained in chapter \ref{feature_selection_5} and get results for every regression method.
\\ \indent
We compared all the different possibilities following the scheme in \ref{fig:all_cases_scheme}.
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{all_cases_scheme.png} 
	\caption{Evaluation possibilities}
    \label{fig:all_cases_scheme}
\end{figure}
\\
To clarify, all regression methods are applied for every feature selection method. The same is valid for the last part, where every regression method is analyzed for every \gls{va} space.
\newpage
\subsection{Best performances}
We observed that the best couple feature selection method and regression approach, for both the \gls{va} in mean and standard deviation is using the \textbf{backward elimination} method and the \textbf{Ridge} regressor.
\\ \indent
An important analysis is that we gain better results not for just audio data type or \gls{eda} type, but for the fusion data type, so it become relevant to use both audio and \gls{eda} combined.
\\ \indent
For the different evaluation spaces, either Valence or Arousal (mean and standard deviation) the Backward elimination algorithm extracted from $30$ to $50$ features.
\\
Understood that the Ridge regression on fusion data with Backward elimination algorithm gives the best results, we decided to calibrate the Ridge regression method.
\\
A parameter of the Ridge regressor is $\alpha$, called \textit{complexity parameter} which controls the amount of shrinkage, the larger value of $\alpha$, the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.
\\
The Ridge coefficients minimize a penalized residual sum of squares:
\begin{equation}
	||y-Xw||^2_2+\alpha ||w||^2_2
\end{equation}
where $X$ is the training data and $y$ the target value (in these cases \gls{va} data) and $w$ the weights.
\\
In the sklean documentation is visible a graph that related the complexity parameter to the weights, shown in figure \ref{fig:ridge_alpha}.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{ridge_alpha.png} 
	\caption{Relationship between complexity parameter $\alpha$ and weights of ridge regressor}
    \label{fig:ridge_alpha}
\end{figure}
\\
We have found better results for small $\alpha$ values, around $\alpha=0.001$.
In the following table, \ref{table:comparisons} are compared results from \gls{pmemo}, results with our model with no feature selection and results in the best case, mentioned before.
\\
Since \gls{pmemo} evaluated their data only on \gls{va} space in mean values, to have a fair comparison here are shown results for mean values of \gls{va}.
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c||c||c|}
		\hline
		Dimension & Scorer & PMEmo & No F.S. & F.S. best \\ [0.5ex] 
		\hline\hline Arousal & RMSE & 0.107 & 0.103 & 0.0417 \\ 
		\hline Valence & RMSE & 0.121 & 0.115 & 0.0435 \\
		\hline Arousal & R2 & 0.764 & 0.769 & 0.780 \\
		\hline Valence & R2 & 638 & 0.645 & 0.834 \\
		\hline
	\end{tabular}
	\caption{Comparisons between PMEmo results, our algorithm with no feature extraction and with feature extraction and best setup of the regressor}
	\label{table:comparisons}
\end{table}

